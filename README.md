# DailyAgentPapers

每日 Arxiv Agent 论文自动摘要 | Daily Arxiv Agent Paper Summaries

## 2026-02-23 (125 篇)

| 分数 | 论文 | 标签 |
|:----:|------|------|
| 9.5 | [OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research](https://arxiv.org/abs/2602.19810) | 多智能体系统, 自主科学研究, Agent架构 |
| 9.5 | [Learning Physical Principles from Interaction: Self-Evolving Planning via Test-Time Memory](https://arxiv.org/abs/2602.20323) | Agent 架构, Agent 自演化, Agent 规划 |
| 9.5 | [HieraMAS: Optimizing Intra-Node LLM Mixtures and Inter-Node Topology for Multi-Agent Systems](https://arxiv.org/abs/2602.20229) | 多智能体系统, Agent架构, LLM混合 |
| 9.5 | [The Single-Multi Evolution Loop for Self-Improving Model Collaboration Systems](https://arxiv.org/abs/2602.05182) | Agent 自演化, 多智能体系统, 模型协作 |
| 9.5 | [Step 3.5 Flash: Open Frontier-Level Intelligence with 11B Active Parameters](https://arxiv.org/abs/2602.10604) | Agent 架构, Agent 推理, 工具使用 |
| 9.5 | [Unifying Evolutionary Prompt Search and Reinforcement Learning for LLM Self-Improvement](https://arxiv.org/abs/2602.14697) | Agent Self-Improvement, Agent Architecture, Reinforcement Learning |
| 9.5 | [AI Agents as Universal Task Solvers](https://arxiv.org/abs/2510.12066) | Agent 架构, Agent 推理, Agent 规划 |
| 9.5 | [Ev-Trust: An Evolutionary Stable Trust Mechanism for Decentralized LLM-Based Multi-Agent Service Economies](https://arxiv.org/abs/2512.16167) | 多智能体系统, 信任机制, 进化博弈论 |
| 9.0 | [Agentic AI for Scalable and Robust Optical Systems Control](https://arxiv.org/abs/2602.20144) | Agent 架构, 工具使用, 多智能体系统 |
| 9.0 | [Agents of Chaos](https://arxiv.org/abs/2602.20021) | Agent 安全, Agent 评测/基准, Agent 架构 |
| 9.0 | [CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence](https://arxiv.org/abs/2602.20048) | Agent 架构, 工具使用, Agent 评测/基准 |
| 9.0 | [Compositional Planning with Jumpy World Models](https://arxiv.org/abs/2602.19634) | 强化学习, 世界模型, 分层规划 |
| 9.0 | [Descent-Guided Policy Gradient for Scalable Cooperative Multi-Agent Learning](https://arxiv.org/abs/2602.20078) | 多智能体系统, 强化学习, 策略梯度 |
| 9.0 | [How to Train Your Deep Research Agent? Prompt, Reward, and Policy Optimization in Search-R1](https://arxiv.org/abs/2602.19526) | Agent 架构, Agentic 强化学习, 工具使用 |
| 9.0 | [OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents](https://arxiv.org/abs/2602.19439) | Agent 架构, 工具使用, 规划与推理 |
| 9.0 | [SkillOrchestra: Learning to Route Agents via Skill Transfer](https://arxiv.org/abs/2602.19672) | Agent 架构, 多智能体系统, Agent 规划/推理 |
| 9.0 | [TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents](https://arxiv.org/abs/2602.19633) | Agent 架构, 工具使用, 规划 |
| 9.0 | [The LLMbda Calculus: AI Agents, Conversations, and Information Flow](https://arxiv.org/abs/2602.20064) | Agent 架构, Agent 安全, 形式化方法 |
| 9.0 | [ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models](https://arxiv.org/abs/2602.20117) | Agent 数据合成, Agentic 强化学习, 推理模型 |
| 9.0 | [NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning](https://arxiv.org/abs/2602.20119) | Agent 架构, 规划, 工具使用 |
| 9.0 | [TROLL: Trust Regions improve Reinforcement Learning for Large Language Models](https://arxiv.org/abs/2510.03817) | 强化学习, 大语言模型, 信任区域 |
| 9.0 | [Mixed-Reality Digital Twins: Leveraging the Physical and Virtual Worlds for Hybrid Sim2Real Transition of Multi-Agent Reinforcement Learning Policies](https://arxiv.org/abs/2403.10996) | 多智能体系统, 强化学习, Sim2Real |
| 9.0 | [EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments](https://arxiv.org/abs/2602.16179) | Agentic Reinforcement Learning, Agent Training, Agent Generalization |
| 9.0 | [From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems](https://arxiv.org/abs/2511.17621) | 多智能体系统, Agent协调, Agent架构 |
| 8.5 | [To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](https://arxiv.org/abs/2602.20055) | Agent 架构, 规划, 工具使用 |
| 8.5 | [Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use](https://arxiv.org/abs/2602.20426) | Agent 工具使用, 工具接口优化, Agent 可靠性 |
| 8.5 | [Quantifying the Expectation-Realisation Gap for Agentic AI Systems](https://arxiv.org/abs/2602.20292) | Agent评测/基准, Agent安全, Agent部署与集成 |
| 8.5 | [LAD: Learning Advantage Distribution for Reasoning](https://arxiv.org/abs/2602.20132) | Agentic Reinforcement Learning, Reasoning, Policy Optimization |
| 8.5 | [Right to History: A Sovereignty Kernel for Verifiable AI Agent Execution](https://arxiv.org/abs/2602.20214) | AI Agent, Agent Security, Verifiable Execution |
| 8.5 | [Towards a Science of AI Agent Reliability](https://arxiv.org/abs/2602.16666) | Agent Reliability, Agent Evaluation, Agent Safety |
| 8.5 | [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842) | Agent 行为模拟, 强化学习, LLM 推理 |
| 8.5 | [PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts](https://arxiv.org/abs/2511.02780) | Agentic Framework, Multi-Agent System, Tool Use |
| 8.5 | [TxRay: Agentic Postmortem of Live Blockchain Attacks](https://arxiv.org/abs/2602.01317) | Agent 架构, 工具使用, Agent 评测/基准 |
| 8.5 | [ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation](https://arxiv.org/abs/2509.21730) | AI助手, 主动性, 个性化 |
| 8.0 | [Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains](https://arxiv.org/abs/2602.19555) | Agent安全, Agent架构, Agent评测/基准 |
| 8.0 | [AgenticSum: An Agentic Inference-Time Framework for Faithful Clinical Text Summarization](https://arxiv.org/abs/2602.20040) | Agent 架构, 工具使用, Agentic 推理 |
| 8.0 | [Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark](https://arxiv.org/abs/2602.19502) | Agentic AI, 多模态, 临床预测 |
| 8.0 | [Interaction Theater: A case of LLM Agents Interacting at Scale](https://arxiv.org/abs/2602.20059) | 多智能体系统, Agent 评测/基准, Agent 交互分析 |
| 8.0 | [MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2602.19843) | 多智能体系统, 可靠性评估, 故障注入 |
| 8.0 | [Skill-Inject: Measuring Agent Vulnerability to Skill File Attacks](https://arxiv.org/abs/2602.20156) | Agent安全, 提示注入攻击, Agent评测基准 |
| 8.0 | [Implicit Intelligence -- Evaluating Agents on What Users Don't Say](https://arxiv.org/abs/2602.20424) | Agent Evaluation, Agent Benchmark, Implicit Reasoning |
| 8.0 | [Watson & Holmes: A Naturalistic Benchmark for Comparing Human and LLM Reasoning](https://arxiv.org/abs/2602.19914) | Agent 评测/基准, 推理评估, 自然主义基准 |
| 8.0 | [MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models](https://arxiv.org/abs/2505.11963) | 多智能体系统, 工具使用, Agent架构 |
| 8.0 | [APEX-Agents](https://arxiv.org/abs/2601.14242) | Agent Benchmark, Agent Evaluation, Long-Horizon Tasks |
| 8.0 | [SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents](https://arxiv.org/abs/2506.08119) | Agent Benchmark, Tool Use, Multi-Step Reasoning |
| 8.0 | [MemoTime: Memory-Augmented Temporal Knowledge Graph Enhanced Large Language Model Reasoning](https://arxiv.org/abs/2510.13614) | Agent Reasoning, Memory-Augmented Systems, Knowledge Graph Integration |
| 8.0 | [LLM-WikiRace Benchmark: How Far Can LLMs Plan over Real-World Knowledge Graphs?](https://arxiv.org/abs/2602.16902) | Agent Benchmark, Planning, Reasoning |
| 7.5 | [Ada-RS: Adaptive Rejection Sampling for Selective Thinking](https://arxiv.org/abs/2602.19519) | Agent 推理, Agent 效率优化, 选择性思考 |
| 7.5 | [Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming](https://arxiv.org/abs/2602.19948) | Agent 评测/基准, Agent 安全, 多智能体系统 |
| 7.5 | [ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making](https://arxiv.org/abs/2602.19458) | 多智能体系统, LLM微调, 决策辅助 |
| 7.5 | [Cost-Aware Diffusion Active Search](https://arxiv.org/abs/2602.19538) | 主动搜索, 多智能体系统, 决策规划 |
| 7.5 | [ISO-Bench: Can Coding Agents Optimize Real-World Inference Workloads?](https://arxiv.org/abs/2602.19594) | Agent Benchmark, Coding Agent, Inference Optimization |
| 7.5 | [Multi-CoLoR: Context-Aware Localization and Reasoning across Multi-Language Codebases](https://arxiv.org/abs/2602.19407) | Agent, 代码智能体, 代码定位 |
| 7.5 | [Pyramid MoA: A Probabilistic Framework for Cost-Optimized Anytime Inference](https://arxiv.org/abs/2602.19509) | Agent 架构, 成本优化, 动态路由 |
| 7.5 | [Representation Stability in a Minimal Continual Learning Agent](https://arxiv.org/abs/2602.19655) | Continual Learning, Agent Architecture, Representation Learning |
| 7.5 | [SAMAS: A Spectrum-Guided Multi-Agent System for Achieving Style Fidelity in Literary Translation](https://arxiv.org/abs/2602.19840) | 多智能体系统, LLM应用, Agent架构 |
| 7.5 | [When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests](https://arxiv.org/abs/2602.19441) | Agent 评测/基准, Agent 协作, 软件工程 |
| 7.5 | [Examining and Addressing Barriers to Diversity in LLM-Generated Ideas](https://arxiv.org/abs/2602.20408) | LLM应用, Agent评测/基准, 人类-AI协作 |
| 7.5 | [DMCD: Semantic-Statistical Framework for Causal Discovery](https://arxiv.org/abs/2602.20333) | 因果发现, LLM应用, 统计验证 |
| 7.5 | [No One Size Fits All: QueryBandits for Hallucination Mitigation](https://arxiv.org/abs/2602.20332) | Agent 评测/基准, Agent 安全, LLM 应用于 Agent 场景 |
| 7.5 | [QuantVLA: Scale-Calibrated Post-Training Quantization for Vision-Language-Action Models](https://arxiv.org/abs/2602.20309) | 模型量化, 具身智能, 视觉-语言-动作模型 |
| 7.5 | [To Reason or Not to: Selective Chain-of-Thought in Medical Question Answering](https://arxiv.org/abs/2602.20130) | 推理优化, 链式思维, 医疗问答 |
| 7.5 | [Latent Introspection: Models Can Detect Prior Concept Injections](https://arxiv.org/abs/2602.20031) | 模型内省, 概念注入, 可解释性 |
| 7.5 | [Contextual Safety Reasoning and Grounding for Open-World Robots](https://arxiv.org/abs/2602.19983) | 机器人安全, 上下文推理, 视觉语言模型 |
| 7.5 | [Janus-Q: End-to-End Event-Driven Trading via Hierarchical-Gated Reward Modeling](https://arxiv.org/abs/2602.19919) | Agent 架构, 强化学习, 决策 |
| 7.5 | [DSDR: Dual-Scale Diversity Regularization for Exploration in LLM Reasoning](https://arxiv.org/abs/2602.19895) | 强化学习, LLM推理, 探索策略 |
| 7.5 | [LLM-enabled Applications Require System-Level Threat Monitoring](https://arxiv.org/abs/2602.19844) | Agent安全, 系统监控, 可靠性 |
| 7.5 | [CodeHacker: Automated Test Case Generation for Detecting Vulnerabilities in Competitive Programming Solutions](https://arxiv.org/abs/2602.20213) | Agent 架构, 自动化测试, 代码生成 |
| 7.5 | [Can Large Language Models Replace Human Coders? Introducing ContentBench](https://arxiv.org/abs/2602.19467) | Agent 评测/基准, LLM 应用于 Agent 场景, 文本标注 |
| 7.5 | [Classroom Final Exam: An Instructor-Tested Reasoning Benchmark](https://arxiv.org/abs/2602.19517) | Agent Benchmark, Reasoning Evaluation, Multimodal Benchmark |
| 7.5 | [Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial](https://arxiv.org/abs/2602.19534) | LLM应用于Agent场景, 多智能体系统, 任务规划 |
| 7.5 | [SenTSR-Bench: Thinking with Injected Knowledge for Time-Series Reasoning](https://arxiv.org/abs/2602.19455) | Agent 推理, 知识注入, 强化学习 |
| 7.5 | [Intent Laundering: AI Safety Datasets Are Not What They Seem](https://arxiv.org/abs/2602.16729) | AI Safety, Adversarial Attacks, Jailbreaking |
| 7.5 | [OckBench: Measuring the Efficiency of LLM Reasoning](https://arxiv.org/abs/2511.05722) | Agent评测/基准, LLM推理, 效率评估 |
| 7.5 | [ContextPilot: Fast Long-Context Inference via Context Reuse](https://arxiv.org/abs/2511.03475) | 推理加速, 长上下文处理, KV缓存优化 |
| 7.5 | [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404) | Agent 架构, 工具使用, 数据合成/提取 |
| 7.5 | [AbstRaL: Augmenting LLMs' Reasoning by Reinforcing Abstract Thinking](https://arxiv.org/abs/2506.07751) | Agent 推理, 强化学习, 抽象思维 |
| 7.5 | [EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization](https://arxiv.org/abs/2602.05165) | 强化学习, 策略优化, 大语言模型 |
| 7.5 | [Personalized Help for Optimizing Low-Skilled Users' Strategy](https://arxiv.org/abs/2411.09109) | Agent 评测/基准, 人机交互, 个性化 Agent |
| 7.5 | [MathScape: Benchmarking Multimodal Large Language Models in Real-World Mathematical Contexts](https://arxiv.org/abs/2408.07543) | Agent Benchmarking, Multimodal Reasoning, Mathematical Reasoning |
| 7.5 | [Think2SQL: Reinforce LLM Reasoning Capabilities for Text2SQL](https://arxiv.org/abs/2504.15077) | 强化学习, 文本到SQL, LLM推理 |
| 7.5 | [Collaborative Document Editing with Multiple Users and AI Agents](https://arxiv.org/abs/2509.11826) | 多智能体系统, 人机协作, Agent 工具使用 |
| 7.5 | [Budget Allocation Policies for Real-Time Multi-Agent Path Finding](https://arxiv.org/abs/2507.16874) | 多智能体系统, 实时路径规划, 预算分配 |
| 7.5 | [PoTable: Towards Systematic Thinking via Plan-then-Execute Stage Reasoning on Tables](https://arxiv.org/abs/2412.04272) | Agent 推理, 规划与执行, 工具使用 |
| 7.5 | [Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight](https://arxiv.org/abs/2511.16175) | Vision-Language-Action (VLA), 机器人控制, 视觉预测 |
| 7.5 | [Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle](https://arxiv.org/abs/2508.05612) | 强化学习, 多模态大语言模型, 后训练 |
| 7.5 | [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620) | 强化学习, 大语言模型微调, 训练稳定性 |
| 7.5 | [EconCausal: A Context-Aware Causal Reasoning Benchmark for Large Language Models in Social Science](https://arxiv.org/abs/2510.07231) | Agent评测/基准, 因果推理, 上下文感知 |
| 7.5 | [Does Your Reasoning Model Implicitly Know When to Stop Thinking?](https://arxiv.org/abs/2602.08354) | 推理模型, 思维链, 采样方法 |
| 7.5 | [CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics](https://arxiv.org/abs/2512.21877) | Agent评测/基准, 领域特定Agent, 多语言Agent |
| 7.5 | [RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models](https://arxiv.org/abs/2602.17053) | Agent 评测/基准, 推理忠实性, 大推理模型 |
| 7.5 | [Bayesian Network Structure Discovery Using Large Language Models](https://arxiv.org/abs/2511.00574) | Agent 推理, LLM 应用于 Agent 场景, 知识表示与推理 |
| 6.5 | [Botson: An Accessible and Low-Cost Platform for Social Robotics Research](https://arxiv.org/abs/2602.19491) | Social Robotics, LLM-Powered Agent, Human-AI Interaction |
| 6.5 | [Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent](https://arxiv.org/abs/2602.19837) | 元学习, 元强化学习, 自适应智能体 |
| 6.5 | [Emergent Manifold Separability during Reasoning in Large Language Models](https://arxiv.org/abs/2602.20338) | LLM Reasoning, Representation Geometry, Chain-of-Thought |
| 6.5 | [Learning to Solve Complex Problems via Dataset Decomposition](https://arxiv.org/abs/2602.20296) | 课程学习, 数据集分解, 教师-学生框架 |
| 6.5 | [RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human Mobility](https://arxiv.org/abs/2509.23115) | LLM应用, 时空预测, 轨迹推理 |
| 6.5 | [Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation](https://arxiv.org/abs/2508.00017) | Agent Reasoning, Deterministic Reasoning, Knowledge Generation |
| 6.5 | [QiMeng-CodeV-R1: Reasoning-Enhanced Verilog Generation](https://arxiv.org/abs/2505.24183) | 强化学习, 代码生成, 数据合成 |
| 6.5 | [Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding](https://arxiv.org/abs/2601.16449) | Multimodal LLM, Emotion Understanding, Benchmark |
| 6.0 | [Advantage-based Temporal Attack in Reinforcement Learning](https://arxiv.org/abs/2602.19582) | 强化学习, 对抗攻击, 时序攻击 |
| 5.5 | [Beyond Mimicry: Toward Lifelong Adaptability in Imitation Learning](https://arxiv.org/abs/2602.19930) | Imitation Learning, Agent Adaptability, Compositional Generalization |
| 5.5 | [RAmmStein: Regime Adaptation in Mean-reverting Markets with Stein Thresholds -- Optimal Impulse Control in Concentrated AMMs](https://arxiv.org/abs/2602.19419) | 强化学习, 最优控制, 去中心化金融 |
| 5.5 | [Recurrent Structural Policy Gradient for Partially Observable Mean Field Games](https://arxiv.org/abs/2602.20141) | Mean Field Games, 强化学习, 部分可观测 |
| 5.5 | [Unlocking Multimodal Document Intelligence: From Current Triumphs to Future Frontiers of Visual Document Retrieval](https://arxiv.org/abs/2602.19961) | 多模态大语言模型, 检索增强生成, Agent系统 |
| 5.5 | [Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking](https://arxiv.org/abs/2602.20330) | 模型可解释性, 多模态模型, 视觉语言模型 |
| 5.5 | [Gap-Dependent Bounds for Nearly Minimax Optimal Reinforcement Learning with Linear Function Approximation](https://arxiv.org/abs/2602.20297) | 强化学习, 线性函数近似, 极小极大优化 |
| 5.5 | [A Very Big Video Reasoning Suite](https://arxiv.org/abs/2602.20159) | 视频推理, 数据集, 评测基准 |
| 5.5 | [CausalFlip: A Benchmark for LLM Causal Judgment Beyond Semantic Matching](https://arxiv.org/abs/2602.20094) | 因果推理, 基准测试, 大语言模型评估 |
| 5.5 | [QUIETT: Query-Independent Table Transformation for Robust Reasoning](https://arxiv.org/abs/2602.20017) | 表格推理, 数据预处理, 查询无关处理 |
| 5.5 | [Temporal-Aware Heterogeneous Graph Reasoning with Multi-View Fusion for Temporal Question Answering](https://arxiv.org/abs/2602.19569) | 知识图谱问答, 时序推理, 图神经网络 |
| 5.5 | [Context Shapes LLMs Retrieval-Augmented Fact-Checking Effectiveness](https://arxiv.org/abs/2602.14044) | LLM 能力评估, 检索增强生成 (RAG), 事实核查 |
| 5.5 | [RefLoRA: Refactored Low-Rank Adaptation for Efficient Fine-Tuning of Large Models](https://arxiv.org/abs/2505.18877) | 模型微调, 参数高效微调, LoRA |
| 5.5 | [Augmenting Lateral Thinking in Language Models with Humor and Riddle Data for the BRAINTEASER Task](https://arxiv.org/abs/2405.10385) | LLM Reasoning, Data Augmentation, Task Formulation |
| 5.5 | [Closing the Gap Between Text and Speech Understanding in LLMs](https://arxiv.org/abs/2510.13632) | 多模态LLM, 语音理解, 模态对齐 |
| 5.5 | [Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions](https://arxiv.org/abs/2505.22147) | 规划, 马尔可夫决策过程, 并发动作 |
| 5.5 | [Inference of Abstraction for a Unified Account of Symbolic Reasoning from Data](https://arxiv.org/abs/2402.08646) | 符号推理, 概率推理, 逻辑推理 |
| 5.5 | [A Simple Generative Model of Logical Reasoning and Statistical Learning](https://arxiv.org/abs/2305.11098) | 逻辑推理, 统计学习, 贝叶斯推理 |
| 5.5 | [Calibrating Large Language Models with Sample Consistency](https://arxiv.org/abs/2402.13904) | LLM Calibration, Confidence Estimation, Model Reliability |
| 5.5 | [Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models](https://arxiv.org/abs/2506.05850) | 大型语言模型, 强化学习, 思维链 |
| 5.5 | [Learning to See the Elephant in the Room: Self-Supervised Context Reasoning in Humans and AI](https://arxiv.org/abs/2211.12817) | Self-Supervised Learning, Contextual Reasoning, Computational Modeling |
| 5.5 | [Bagpiper: Solving Open-Ended Audio Tasks via Rich Captions](https://arxiv.org/abs/2602.05220) | 音频基础模型, 多模态理解与生成, 任务无关推理 |
| 4.0 | [Effects of Property Recovery Incentives and Social Interaction on Self-Evacuation Decisions in Natural Disasters: An Agent-Based Modelling Approach](https://arxiv.org/abs/2602.19639) | Agent-Based Modeling, Multi-Agent Systems, Evolutionary Game Theory |
| 4.0 | [Federated Causal Representation Learning in State-Space Systems for Decentralized Counterfactual Reasoning](https://arxiv.org/abs/2602.19414) | 联邦学习, 因果表示学习, 状态空间模型 |
| 4.0 | [U2-BENCH: Benchmarking Large Vision-Language Models on Ultrasound Understanding](https://arxiv.org/abs/2505.17779) | 多模态大模型, 基准测试, 医学影像 |

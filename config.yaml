# DailyAgentPapers 配置文件

# ============================================================
# arxiv 搜索配置
# ============================================================

# arxiv API 搜索关键词（宽泛搜索，用于第一层过滤）
search_keywords:
  - "agent"
  - "multi-agent"
  - "multi agent"
  - "MAS"
  - "tool use"
  - "tool-use"
  - "agent memory"
  - "agentic"
  - "agentic RL"
  - "reasoning"
  - "CoT"
  - "chain of thought"
  - "chains of thought"

# arxiv 类别
categories:
  - "cs.AI"
  - "cs.CL"
  - "cs.MA"
  - "cs.LG"
  - "cs.SE"

# 关键词精筛（第二层过滤，标题或摘要中至少包含一个）
filter_keywords:
  - "agent"
  - "agents"
  - "agentic"
  - "multi-agent"
  - "multiagent"
  - "tool use"
  - "tool calling"
  - "function calling"
  - "planning"
  - "reasoning"
  - "chain of thought"
  - "chain-of-thought"
  - "self-reflection"
  - "self-improve"
  - "self-evolve"
  - "memory"
  - "retrieval augmented"
  - "RAG"
  - "reinforcement learning from human"
  - "GRPO"
  - "reward model"
  - "MCP"
  - "model context protocol"
  - "orchestrat"
  - "workflow"
  - "autonomous"
  - "self-play"
  - "code generation"
  - "code agent"
  - "web agent"
  - "embodied"
  - "grounding"
  - "environment"
  - "benchmark"
  - "evaluation"
  - "instruction following"
  - "alignment"
  - "LLM"
  - "large language model"
  - "foundation model"
  - "GPT"
  - "Claude"
  - "Gemini"
  - "DeepSeek"
  - "Kimi"
  - "GLM"
  - "Minimax"
  - "Qwen"
  - "reasoning"
  - "CoT"
  - "chain of thought"
  - "chains of thought"
  - "tool-use"

# 加分关键词（出现越多，越可能是核心 Agent 论文）
boost_keywords:
  - "agent"
  - "multi-agent"
  - "tool use"
  - "planning"
  - "memory"
  - "reasoning"
  - "self-reflection"
  - "autonomous"
  - "agentic"
  - "MCP"
  - "orchestration"
  - "ReAct"
  - "code generation"
  - "web agent"
  - "skills"
  - "multi agent"
  - "tool-use"
  - "CoT"
  - "chain of thought"
  - "chains of thought"

# 最大搜索结果数
max_results: 500

# 更新论文抓取配置（捕获在目标日期修订的 v2+ 论文）
updates:
  fetch_updates: true
  max_results_updates: 500
  # 更新论文的最早发布日期（过滤掉 LLM 时代之前的老论文）
  min_published_date: "2023-01-01"

# LLM 请求并发数（预评分 + 逐篇处理）
concurrency: 2

# ============================================================
# LLM 配置
# ============================================================
llm:
  # 温度
  temperature: 0.3
  # 分步模式：单个 Q&A 的最大输出 token 数
  max_tokens_single_qa: 2000
  # 一次性模式（回退）：有全文时的最大输出 token 数
  max_tokens_with_content: 5000
  # 一次性模式（回退）：仅摘要时的最大输出 token 数
  max_tokens_abstract_only: 3000
  # 低于此分数的论文将被过滤
  min_relevance_score: 4
  # prompt 模板位于 scripts/prompts/ 目录下，可直接编辑文本文件

# ============================================================
# 论文全文获取配置
# ============================================================
paper_content:
  # 全文最大字符数（截断保护，防止超出 LLM 上下文窗口）
  max_content_length: 50000
  # 分步模式：每个 section 提取的最大字符数
  max_section_chars: 15000
  # 章节规划时每个 section 的内容预览字符数（0 表示仅标题）
  section_preview_chars: 256
  # arxiv-to-prompt LaTeX 获取选项
  latex:
    keep_comments: false
    remove_appendix_section: true
    use_cache: true

# ============================================================
# 网络请求配置
# ============================================================
network:
  user_agent: "DailyAgentPapers/1.0"
  # arxiv 库请求间隔（秒），防止限流
  arxiv_request_delay: 7.0
  arxiv_retries: 4
  # PDF 下载 / LLM API 请求
  request_timeout: 90

# ============================================================
# 输出配置
# ============================================================
output:
  # 文件名 slug 最大长度
  slug_max_length: 80
  # frontmatter 中最大作者数
  max_authors_frontmatter: 20
  # JSON 中最大作者数
  max_authors_json: 5
  # README 中最大标签数
  max_tags_readme: 5
  # README 中摘要截断长度
  summary_truncate_length: 1024

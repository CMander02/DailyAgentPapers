---
title: "Codified Context: Infrastructure for AI Agents in a Complex Codebase"
authors:
  - "Aristidis Vasilopoulos"
date: "2026-02-24"
arxiv_id: "2602.20478"
arxiv_url: "https://arxiv.org/abs/2602.20478"
pdf_url: "https://arxiv.org/pdf/2602.20478v1"
categories:
  - "cs.SE"
tags:
  - "Agent Architecture"
  - "Multi-Agent Systems"
  - "Agent Memory"
  - "Tool Use"
  - "Agentic Software Engineering"
  - "Agent Coordination"
  - "Knowledge Base"
  - "Persistent Memory"
relevance_score: 9.0
---

# Codified Context: Infrastructure for AI Agents in a Complex Codebase

## 原始摘要

LLM-based agentic coding assistants lack persistent memory: they lose coherence across sessions, forget project conventions, and repeat known mistakes. Recent studies characterize how developers configure agents through manifest files, but an open challenge remains how to scale such configurations for large, multi-agent projects. This paper presents a three-component codified context infrastructure developed during construction of a 108,000-line C# distributed system: (1) a hot-memory constitution encoding conventions, retrieval hooks, and orchestration protocols; (2) 19 specialized domain-expert agents; and (3) a cold-memory knowledge base of 34 on-demand specification documents. Quantitative metrics on infrastructure growth and interaction patterns across 283 development sessions are reported alongside four observational case studies illustrating how codified context propagates across sessions to prevent failures and maintain consistency. The framework is published as an open-source companion repository.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决基于大语言模型的AI编程助手在复杂大型代码库中缺乏持久记忆能力的问题。研究背景是当前如GitHub Copilot等AI编码代理已广泛使用，并能执行复杂的开发任务，但它们存在“会话失忆”的固有缺陷：每个新会话都从零开始，无法记住项目历史、既定规范或以往错误，导致跨会话工作缺乏连贯性，重复犯错，且难以维持项目一致性。

现有方法的不足主要体现在：虽然已有研究通过清单文件（如.cursorrules）来配置代理，但这种单文件配置模式无法扩展到大型、多代理协作的项目中。对于小型原型项目，单一提示可能足够描述整个代码库，但对于像论文中涉及的10.8万行C#分布式系统这样的大型复杂项目，单文件清单无法承载所有必要的项目知识、约定和规范，导致知识传递不可靠、不可扩展。

本文要解决的核心问题是：如何为复杂代码库中的多AI代理系统，设计一个可扩展的、结构化的“编码化上下文”基础设施，以实现持久的项目记忆。具体而言，论文提出了一个三层架构来解决此问题：1）一个作为“热记忆”的章程，编码始终需要加载的项目惯例、检索钩子和协调协议；2）19个专门化的领域专家代理，各自嵌入特定知识；3）一个作为“冷记忆”的按需知识库，包含34份机器可读的规范文档。该基础设施将文档视为“承重构件”，使AI代理即使在复杂代码库中也能模拟持久记忆，从而确保跨会话的一致性输出，防止错误，并支持领域专家在非专业领域进行软件开发。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为以下几类：

**1. 代理配置与清单文件研究：** 多项实证研究分析了开发者如何通过创建 CLAUDE.md、.cursorrules 或 AGENTS.md 等清单文件，为 AI 编码代理提供项目特定指令。这些研究对指令类型进行了分类，并初步量化了其效果（如使用 AGENTS.md 可减少运行时间和令牌消耗）。本文的研究起点与此类似，但核心关注点不同：当项目知识需求超出单个文件容量时（即“规模化”问题）应如何应对。本文描述的架构从类似清单文件演化而来，但其规模（约 26,000 行）远超先前研究中的典型清单。

**2. 上下文工程与知识组织：** 上下文工程已被确立为一个学科，并提出了如“生成-反思-策展”的循环框架。相关工作指出存在“简洁性偏差”，即迭代优化易导致提示词变得简短而通用。本文的发现与此一致，并进一步表明，要使专用代理可靠工作，需要嵌入大量领域知识。本文提出的分层知识组织架构，是对如何结构化代理所依赖知识的具体实践，旨在实现跨工具的可移植性，而非绑定于特定平台（如 Google Conductor）。

**3. 多代理系统与工作流：** 已有如 AutoGen、ChatDev 和 MetaGPT 等多代理协调框架，主要解决代理间通信、任务阶段划分和流程嵌入等问题。本文的工作是互补的：这些框架定义了代理“如何”协调，而本文则聚焦于构建代理所依赖的知识“内容”本身。此外，研究表明集成多工具工作流在生成多文件代码时成功率高于单代理系统，本文采用的多专家代理架构与此原则相符。

**4. 代码检索与基准评测：** 以 Cursor 的代码库索引为代表的工具，通过嵌入检索直接在代码本身中查找信息。本文的“代码化上下文”基础设施与之不同，它索引的是“关于代码的知识”（如设计意图、约束、已知故障模式），这些信息并不直接存在于任何单一源文件中。在评测方面，SWE-bench 等基准专注于评估独立任务上的自主问题解决，而本文则针对持续、人工指导的开发场景，其中规范尤其需要编码架构意图和设计约束。

**5. 领域知识增强：** 研究普遍表明，用编码化的人类专家领域知识增强 LLM 可以提高输出质量。本文方法遵循这一原则，但将其应用于“项目规模”，知识库主要捕获项目特定的惯例、架构决策和已知故障模式，而非通用的领域专业知识。

### Q3: 论文如何解决这个问题？

论文通过构建一个三层级的“编码化上下文”基础设施来解决基于LLM的智能编码助手缺乏持久记忆、会话间失去连贯性、遗忘项目惯例以及重复已知错误的问题。该架构将项目知识工程化为明确供AI消费的结构化文档，而非仅仅优化单个提示。

**整体框架与核心组件**：
该基础设施包含三个层级，具有不同的加载策略和更新频率：
1.  **第一层：宪法（热内存）**：一个始终加载的单一Markdown文件（约660行），定义了代码质量标准、命名约定、构建命令、架构模式摘要（引用第三层详细文档）、常见操作清单、已知故障模式以及将任务路由到专业代理的编排协议。其核心设计约束是简洁性，确保能完整载入每个会话而不消耗过多上下文窗口。宪法嵌入了“触发表”，根据被修改的文件等信号，将任务自动路由到相应的专业代理。
2.  **第二层：专业代理（领域专家）**：包含19个专业代理规范文件（Markdown，总计约9300行），每个代理针对代码库的特定领域（如网络协议、坐标系统、代码审查）。这些代理分为高能力代理（8个，处理复杂领域）和标准能力代理（11个，处理聚焦任务）。每个规范定义了领域范围、可用工具和权限、相关第三层文档、输出格式期望以及常见领域错误。关键创新在于，超过一半的规范内容是项目特定的领域知识（代码库事实、公式、代码模式、已知故障模式），而非行为指令，这构成了与第三层的“有意重叠”。
3.  **第三层：知识库（冷内存）**：包含34个按需检索的Markdown文档（约16250行），每个文档详细记录一个子系统。文档专为AI消费编写，包含明确的代码模式、文件路径、参数名和预期行为。这些是“活的文档”，由AI在开发者指导下生成和更新。知识库通过一个定制的模型上下文协议服务器提供，该服务器索引文档并提供关键词搜索等工具。

**关键技术方法与创新点**：
*   **分层记忆与加载策略**：明确区分“始终加载”（宪法）、“按任务调用”（代理）和“按需检索”（知识库）的上下文，优化了上下文窗口的使用并确保了核心规则的持久性。
*   **知识嵌入与有意重叠**：专业代理规范中直接嵌入大量项目特定知识，而非完全依赖检索。这解决了在复杂、易出错的领域中，代理缺乏预加载上下文时错误率显著增加的问题（与简洁性偏见现象一致），确保了代理拥有执行任务所需的完整心智模型。
*   **基于触发表的自动编排**：宪法中的触发表根据文件模式等信号自动将任务路由到合适的专业代理，消除了开发者记忆调用哪个代理的负担，并编码了关于每个文件区域所需领域知识的制度性知识，解决了先前工作中提到的代理间错位和规划者-编码者差距问题。
*   **以失败模式驱动的代理创建**：代理的创建通常由观察到的失败模式驱动，而非预先设计。当某个领域的任务反复需要重新解释相同知识时，就将这些知识编码到代理规范中。这种实践启发式方法提高了问题解决效率。
*   **专为AI消费的知识工程**：整个基础设施（宪法、代理规范、知识库文档）都明确以AI为主要受众进行编写和结构化，将项目知识本身视为可精心设计的软件工件，而不仅仅是优化提示。

### Q4: 论文做了哪些实验？

论文的实验部分主要围绕一个长达70天、包含283个开发会话的真实项目展开，旨在评估所提出的“编码化上下文”基础设施的规模、增长和交互模式。实验设置基于一个108,256行C#代码的分布式系统项目，基础设施本身包含54个文件（约26,200行），占代码总量的24.2%。数据集和基准测试主要来源于项目的Git历史记录和1,457个JSONL格式的会话历史文件（部分早期数据有缺失）。对比方法方面，论文未与传统AI助手进行严格的量化对比，而是通过内部交互模式分析（如结构化会话与临时会话的对比）来体现基础设施的影响。

主要结果通过量化指标和四个观察性案例研究呈现。关键量化指标包括：基础设施的三个层级（T1宪法、T2专家Agent、T3知识库）随项目三个发展阶段（第1-10天、11-30天、31-57天）的文件和代码行数增长轨迹；在283个会话中，共记录了2,801次人类提示、1,197次Agent调用和16,522次自主Agent交互；约13%的会话为结构化工作流（计划-执行-评审），87%为临时会话；在757次可分类的Agent调用中，57%（432次）调用的是项目定制的专家Agent，其中最常用的是代码审查员（154次）和网络协议设计员（85次）；知识库通过MCP服务被检索了1,478次，涉及218个会话。

四个案例研究定性地展示了编码化上下文在防止错误、保持一致性方面的作用，例如保存系统规范在74个会话中被引用，确保了后续五个相关功能实现无误；UI同步模式文档则捕获了解决网络消息传递问题的经验。这些结果表明，该基础设施能够支持跨会话的知识持久化和一致性应用。

### Q5: 有什么可以进一步探索的点？

基于论文讨论部分，可以进一步探索的点包括：首先，该基础设施高度依赖人工编写和维护规范，未来可研究如何自动化生成和更新“冷记忆”知识库，例如通过代码变更历史、提交信息或团队讨论记录自动提炼规范。其次，当前系统在19个专用代理间的协调机制可能较为刚性，未来可探索更动态、自适应的多智能体协作框架，使代理能根据任务复杂度自主重组或调用新专家。此外，论文提到规范过时会导致静默失败，未来需设计更鲁棒的验证机制，如让代理对规范提出质疑或通过测试反馈自动检测不一致性。最后，该研究基于单一大型C#项目，其模式在不同编程语言、项目规模或团队结构中的普适性有待验证，可探索跨领域、跨技术的通用上下文编码框架。

### Q6: 总结一下论文的主要内容

该论文针对基于大语言模型的AI编程助手在复杂代码库中缺乏持久记忆、难以维持跨会话一致性的问题，提出了一套“编码化上下文”基础设施。核心贡献在于设计了一个包含三个组件的系统架构：一是作为“热记忆”的章程文件，用于编码项目规范、检索钩子和协调协议；二是19个特定领域专家智能体；三是作为“冷记忆”的、包含34份按需规范文档的知识库。该框架在一个10.8万行C#分布式系统的构建过程中开发并验证。论文通过283个开发会话的量化指标（如基础设施增长和交互模式）以及四个观察性案例研究，展示了该基础设施如何跨会话传播上下文，从而有效防止错误、维持项目一致性并提升多智能体协作的可扩展性。其意义在于为大型、多智能体软件项目提供了一种系统化的、可扩展的配置与管理范式，相关框架已开源。

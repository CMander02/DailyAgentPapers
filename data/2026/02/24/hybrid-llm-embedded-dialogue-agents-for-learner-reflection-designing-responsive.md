---
title: "Hybrid LLM-Embedded Dialogue Agents for Learner Reflection: Designing Responsive and Theory-Driven Interactions"
authors:
  - "Paras Sharma"
  - "YuePing Sha"
  - "Janet Shufor Bih Epse Fofang"
  - "Brayden Yan"
  - "Jess A. Turner"
  - "Nicole Balay"
  - "Hubert O. Asare"
  - "Angela E. B. Stewart"
  - "Erin Walker"
date: "2026-02-24"
arxiv_id: "2602.20486"
arxiv_url: "https://arxiv.org/abs/2602.20486"
pdf_url: "https://arxiv.org/pdf/2602.20486v1"
categories:
  - "cs.HC"
  - "cs.AI"
tags:
  - "对话系统"
  - "LLM应用"
  - "混合架构"
  - "教育Agent"
  - "人机交互"
  - "反思支持"
  - "理论驱动设计"
  - "上下文响应"
relevance_score: 7.5
---

# Hybrid LLM-Embedded Dialogue Agents for Learner Reflection: Designing Responsive and Theory-Driven Interactions

## 原始摘要

Dialogue systems have long supported learner reflections, with theoretically grounded, rule-based designs offering structured scaffolding but often struggling to respond to shifts in engagement. Large Language Models (LLMs), in contrast, can generate context-sensitive responses but are not informed by decades of research on how learning interactions should be structured, raising questions about their alignment with pedagogical theories. This paper presents a hybrid dialogue system that embeds LLM responsiveness within a theory-aligned, rule-based framework to support learner reflections in a culturally responsive robotics summer camp. The rule-based structure grounds dialogue in self-regulated learning theory, while the LLM decides when and how to prompt deeper reflections, responding to evolving conversation context. We analyze themes across dialogues to explore how our hybrid system shaped learner reflections. Our findings indicate that LLM-embedded dialogues supported richer learner reflections on goals and activities, but also introduced challenges due to repetitiveness and misalignment in prompts, reducing engagement.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决如何设计一个既能遵循教育学理论、又能灵活响应用户动态输入的对话系统，以支持学习者在开放学习环境中的反思活动。研究背景是，传统的基于规则（如对话树、状态机）的对话系统能够依据自我调节学习（SRL）等理论提供结构化支架，但其响应模式僵化，难以适应学习者多变的投入状态和开放式表达。另一方面，新兴的大语言模型（LLM）虽能生成上下文敏感的回应，但其设计缺乏教育学理论指导，可能无法有效引导符合学习科学原理的深度反思。现有方法因此存在“理论对齐但响应不足”与“响应灵活但理论缺失”之间的割裂。

本文的核心问题是：如何构建一种混合架构的对话系统，将LLM的生成能力嵌入到理论驱动的规则框架中，从而在支持学习者反思时，既能确保对话的理论一致性，又能实现动态的上下文响应。具体而言，系统需在机器人设计夏令营这一文化响应性学习环境中，引导中学生对目标、计划和行动进行反思，并探索这种混合设计在引发反思、促进深度对话以及影响学习者感知方面的效果。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：支持学习者反思的对话系统设计、基于大语言模型（LLM）的对话系统，以及混合架构的对话系统。

在**支持学习者反思的对话系统设计**方面，已有大量基于规则的系统。这些系统通常基于自我调节学习（SRL）等理论框架，通过预定义的决策树或状态机提供结构化的反思支架。例如，相关研究开发了脚本化对话代理来支持学生在SRL过程中的监控与反思，或设计了包含元认知和行动中反思技巧的聊天机器人。这些系统的优势在于可预测、可解释且与理论框架紧密结合，但对话流程受限，难以适应预设计范围之外的对话情境或进行灵活跟进。

在**基于LLM的对话系统**方面，近期研究利用LLM的上下文理解与生成能力，构建能够进行自由形式、情境敏感交互的反思对话系统。例如，LLM被用于生成情境化的AI日志提示、促进自我反思，或作为对话式导师帮助学习者进行战略性思考。在教育领域，也有研究使用ChatGPT等LLM在物理学习或计算机科学学习中激发元认知过程。然而，LLM并非针对特定学习理论设计，其输出可能流于表面或与学习者的元认知及策略需求不一致。

在**混合架构对话系统**方面，研究致力于结合规则系统的结构化支架与LLM的生成灵活性。典型设计包括用规则决定何时调用生成模型、生成结构化提示供LLM细化，以及对LLM输出进行过滤。例如，有研究将LLM与脚本化辅导理论提示结合，为家长提供对话建议；或通过融入学生反应模型和教学评估标准来微调LLM导师模型。与本文工作最为接近的是一项结合状态机和LLM来引导儿童分享个人事件及情感的研究。本文的混合系统与之类似，但关键区别在于：本文首先基于SRL的“反应与反思”阶段设计规则化对话模板，然后将LLM作为决策者嵌入其中，仅在学习者对规则化提示的回应模糊或不相关时，才触发LLM以生成促进深度反思的跟进提示。这种方式确保了理论驱动的人类设计提示得以传递，同时利用LLM对学习者的自由形式反思进行情境化响应。

综上，本文与相关工作的关系在于，它继承了规则系统与理论对齐的优点，并融入了LLM的响应灵活性。其区别在于提出了一种特定的混合嵌入策略：LLM并非用于每个阶段的自由对话，而是作为基于规则模板的、受控的决策与延伸生成组件，以此在保证教学意图的同时增强对话的响应性。

### Q3: 论文如何解决这个问题？

论文通过设计一个混合架构的对话系统来解决传统规则系统灵活性不足与大语言模型（LLM）缺乏理论指导之间的矛盾。其核心方法是将LLM的上下文响应能力嵌入到一个基于自调节学习（SRL）理论构建的、规则驱动的有限状态机（FSM）框架中，从而在保证教学理论对齐的同时，实现对学习者动态参与度的响应。

整体框架是一个以FSM建模的对话流程。主要模块包括：
1.  **规则基础组件**：作为系统的骨干，实现为一个有限状态机。它定义了一系列对话状态（如建立关系、回顾目标、制定计划、反思设计等），这些状态严格对应SRL理论中的“反应与反思”阶段。对话按预设状态序列推进，每个状态节点包含系统提示（规则化提示），并规定了学习者所需的响应类型（如选择菜单项或自由文本）。
2.  **LLM嵌入组件**：作为系统的响应引擎，仅在学习者对开放式反思提示给出自由文本回答时被触发。它采用一个两阶段流水线工作：
    *   **相关性检查阶段**：LLM充当二元判断器，评估学习者的回答是否与当前系统提示足够“相关”（即是否包含充分细节或反思性）。判断基于动态提示进行，该提示注入了针对每个规则提示的“字段信息”（即需要寻找的特定反思要素），并辅以少量示例（few-shot examples）和推理轨迹。
    *   **上下文生成阶段**：如果相关性检查结果为“否”，LLM不会推进状态机，而是基于一个包含对话历史（最近10轮）、特定提示信息和少量示例的新提示，生成一个有针对性的、情境化的后续追问，以引导学习者进行更深入的反思。

关键技术流程如下：系统首先显示规则基础提示。学习者回应后，若为开放式反思回答，则触发LLM进行相关性检查。若通过，系统按FSM进入下一状态；若未通过，则LLM进入生成阶段，产生一个追问。此循环持续，直到学习者回答通过相关性检查或达到最多三次追问的限制（防止陷入死循环或挫伤学习者积极性），之后系统将默认回归到规则基础流程并推进状态。

创新点主要体现在：
1.  **理论指导与灵活响应的混合**：用规则FSM确保对话结构符合成熟的教学理论（SRL），为反思提供结构化支架；同时，在关键节点引入LLM，使其能在理论框架内，根据实时对话上下文动态生成追问，弥补了纯规则系统应对突发性、不充分回答的不足。
2.  **两阶段LLM流水线设计**：通过“检查-生成”的分离，使LLM仅在必要时（回答不充分时）介入生成，既降低了计算开销，又避免了LLM可能脱离理论框架的随意发挥。相关性检查中的“字段信息”注入和少量示例引导，是约束LLM判断、使其与教学意图对齐的关键。
3.  **工程与伦理考量**：系统采用本地部署的较小参数模型（LLaMa-3.1-8B-Instruct），在保护学习者隐私数据不外泄的前提下，通过针对性的提示工程和领域数据评估，实现了与更大模型相近的任务性能。前端集成语音交互功能，后端通过WebSocket实现前后端解耦，增强了系统的可用性和可扩展性。

### Q4: 论文做了哪些实验？

本研究在一个为期两周的机器人夏令营中进行了用户研究，共有14名4至8年级的学习者参与，其中9人（7名女孩，2名男孩）最终完成了与对话系统的交互并提供了有效数据。实验设置上，对话交互发生在夏令营的第六和第七天，此时学习者已初步形成机器人设计想法。每位学习者与一个独立的混合对话系统实例进行了一次持续5-10分钟的对话，对话具有固定的开始和结束状态。该系统将基于自我调节学习理论的规则框架与大型语言模型（LLM）的上下文响应能力相结合，旨在促进学习者的反思。

数据集来源于这9名学习者的对话交互文本以及随后的半结构化访谈录音转录。研究者对对话数据进行了定性的主题编码分析，主要类别包括：LLM触发（如针对目标、计划的提问）、LLM重新提示（根据上下文相关性判断）、学习者反思（对设计目标、计划、行动或感受的思考）、情感（积极、消极或中性）和参与度（高参与度表现为详细回答，低参与度表现为简短拒绝）。两位研究者对所有对话进行了编码，Cohen's Kappa系数为0.81，表明编码一致性良好。

主要结果通过分析编码后的对话主题得出。研究发现，嵌入LLM的对话能够支持学习者对目标和活动进行更丰富的反思。然而，也暴露出一些挑战：LLM的提示有时会出现重复以及与对话情境不匹配的情况，这降低了学习者的参与度。具体而言，分析归纳出五个关键主题：鼓励详细回答、上下文错位、重复性、互动意愿以及情感语调的变化。这些发现表明，混合方法在提供理论对齐的结构化支架的同时，利用LLM的响应性深化了反思，但其提示的准确性和多样性仍需改进以避免负面影响。

### Q5: 有什么可以进一步探索的点？

该论文的混合架构虽结合了理论严谨性与LLM的灵活性，但仍存在明显局限。首先，系统依赖规则框架可能限制LLM的动态适应能力，导致提示重复或错位，影响学习投入度。其次，研究仅在特定夏令营场景验证，缺乏跨学科、跨文化环境的普适性检验。未来可探索以下方向：一是引入强化学习机制，让LLM基于实时对话反馈优化提示策略，减少机械重复；二是构建多模态交互（如结合语音、手势），增强情境感知能力；三是开发可解释性模块，使LLM的决策过程更透明，便于教育者调整理论框架。此外，可尝试分层混合模型，将宏观学习阶段交由规则控制，微观对话生成交由LLM动态适配，以平衡结构性与灵活性。

### Q6: 总结一下论文的主要内容

该论文提出了一种混合型对话系统，将大型语言模型（LLM）的响应能力嵌入到基于规则的理论框架中，旨在支持学习者的反思过程。核心问题是传统基于规则的系统虽能提供符合教学理论的结构化支架，但难以灵活应对学习者参与度的变化；而纯LLM虽能生成上下文敏感的回应，却缺乏教育理论指导，可能偏离有效的学习互动设计。

论文的方法概述是构建一个混合架构：系统以自我调节学习理论为基础，通过规则框架确保对话的理论一致性，同时利用LLM实时分析对话上下文，动态决定何时以及如何提示学习者进行更深层次的反思。该系统在一个文化响应性机器人夏令营中进行了部署和评估。

主要结论表明，这种混合方法确实促进了学习者对目标和活动更丰富的反思，证明了结合理论指导与LLM灵活性的价值。然而，研究也发现LLM的提示有时存在重复性或与情境不匹配的问题，这反而降低了学习者的参与度。因此，论文的核心贡献在于为教育对话系统设计提供了一种平衡理论对齐与上下文响应性的新范式，并指出了未来需优化LLM提示以更好维持学习动力的方向。

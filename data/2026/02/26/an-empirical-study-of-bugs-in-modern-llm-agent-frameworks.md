---
title: "An Empirical Study of Bugs in Modern LLM Agent Frameworks"
authors:
  - "Xinxue Zhu"
  - "Jiacong Wu"
  - "Xiaoyu Zhang"
  - "Tianlin Li"
  - "Yanzhou Mu"
  - "Juan Zhai"
  - "Chao Shen"
  - "Chunrong Fang"
  - "Yang Liu"
date: "2026-02-25"
arxiv_id: "2602.21806"
arxiv_url: "https://arxiv.org/abs/2602.21806"
pdf_url: "https://arxiv.org/pdf/2602.21806v2"
categories:
  - "cs.SE"
tags:
  - "Agent 框架"
  - "实证研究"
  - "系统可靠性"
  - "Agent 评测/基准"
  - "Agent 生命周期"
  - "Bug 分析"
relevance_score: 8.0
---

# An Empirical Study of Bugs in Modern LLM Agent Frameworks

## 原始摘要

LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决大型语言模型（LLM）智能体框架中存在的缺陷（bug）问题，这是一个在LLM软件供应链中至关重要但被现有研究忽视的领域。随着LLM在智能问答、自动化软件工程等实际应用中的快速发展，单一的模型调用已无法支持需要长期规划和工具使用的复杂任务，因此催生了集成记忆、工具和控制逻辑的智能体范式。诸如LangChain等智能体框架应运而生，用于支持任务工作流定义、状态管理和多智能体协调。

然而，现有研究主要聚焦于智能体层面的失败，例如在推理、规划或行动过程中的行为偏差，通常通过行为分析或基准测试进行评估。这些研究虽然增进了对智能体行为及模型局限性的理解，但很大程度上忽略了根植于底层智能体框架本身的缺陷。近期虽有工作开始分析智能体库的bug，但其方法（如将拉取请求映射到静态库组件）忽略了智能体动态执行和时序工作流的特性。因此，框架级缺陷如何在整个动态的智能体生命周期中显现，其根本原因和可观察症状是什么，仍然是一个未被探索的空白。

针对这一不足，本文的核心问题是：对现代LLM智能体框架中的缺陷进行系统的实证研究，以理解其根本原因、可观察症状及其在智能体生命周期各阶段的分布与关联。论文通过手动分析来自CrewAI和LangChain的998份缺陷报告，构建了一个涵盖15种根本原因和7种症状的分类体系，并将其映射到“智能体初始化”、“感知”、“自我行动”、“相互交互”和“演化”这五个智能体生命周期阶段。研究发现，框架缺陷主要源于“API误用”、“API不兼容”和“文档不同步”，且高度集中在“自我行动”阶段，症状则主要表现为“功能错误”、“崩溃”和“构建失败”，反映了对任务进程和控制流的破坏。这项研究填补了框架级缺陷认知的空白，为加强LLM软件供应链的质量提供了重要见解。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为两大类：**Agent层面的失效研究**和**框架/库层面的缺陷研究**。

在**Agent层面的失效研究**方面，现有工作主要关注智能体在推理、规划和行动过程中的行为失败，通常通过行为分析或基准测试进行评估。这些研究增进了对Agent行为模式及模型能力局限的理解，但主要聚焦于Agent应用逻辑本身，**未深入探究底层支撑框架（Framework）的缺陷**。本文则填补了这一空白，将研究对象从Agent行为转向了支撑其运行的框架代码。

在**框架/库层面的缺陷研究**方面，近期有工作开始分析Agent相关代码库（Library）的缺陷，例如通过映射Pull Request到库的静态组件（如数据预处理模块）。然而，这类方法**忽略了Agent动态执行和时序性工作流的特点**。本文与这类工作的核心区别在于，**引入了面向Agent生命周期的视角**，将框架缺陷映射到“智能体初始化”、“感知”、“自主行动”、“相互交互”和“进化”五个动态阶段进行分析，从而能够系统地揭示缺陷在动态执行流程中如何产生和传播。

因此，本文与现有研究的关系是**补充和深化**。它继承了实证研究的方法论，但将研究对象从Agent行为或静态库组件，转向了动态的、生命周期中的框架级缺陷，并构建了相应的根因与症状分类体系。

### Q3: 论文如何解决这个问题？

论文通过一个严谨的三步实证研究方法来解决对智能体框架层面缺陷缺乏理解的问题。其核心方法是系统性地收集、筛选和分类来自两个主流开源LLM智能体框架（CrewAI和LangChain）的缺陷报告，并构建一个以智能体生命周期为导向的分类体系。

整体框架分为三个主要步骤：1) 问题收集：从CrewAI和LangChain的GitHub仓库中全面抓取共2773个原始议题报告，涵盖开放和关闭的议题以减少抽样偏差。2) 缺陷过滤：采用两阶段过滤流程确保数据质量。首先利用GitHub的“bug”标签进行初步筛选，得到1010个报告；随后进行人工审查，排除文档错字、使用问题、基础设施问题等无关报告，最终得到998个与框架缺陷直接相关的有效报告。3) 个体标注：由两位作者担任标注员，分两阶段进行。第一阶段，随机抽取100份报告进行初步分析，通过独立检查、识别涉及组件、推断根因、记录症状，并对不一致处进行讨论达成共识，从而构建出包含15个根因类别和7个症状类别的初始分类法。第二阶段，将该分类法应用于剩余的大规模报告进行标注，仅在遇到无法归入现有类别的新情况时才引入新类别。

关键技术与创新点在于：首先，研究视角从常见的“智能体级”失败转向了被忽视的“框架级”缺陷。其次，方法论上结合了自动化标签筛选与严格的人工审查，确保了缺陷数据集的高度相关性。最重要的是，构建了一个结构化的、面向生命周期的分类体系，将识别出的根因和症状映射到智能体生命周期的五个阶段（智能体初始化、感知、自我行动、相互交互、进化），这为系统性地理解和分析框架缺陷的模式、分布（如发现缺陷主要集中在“自我行动”阶段）及影响提供了坚实的基础。整个方法的设计注重可靠性（如双人独立标注与交叉核对）和全面性，旨在填补该领域实证知识的空白。

### Q4: 论文做了哪些实验？

本研究对CrewAI和LangChain两个现代LLM智能体框架中的998个错误报告进行了实证分析。实验设置包括对这两个开源框架GitHub仓库中真实错误报告的收集、分类和标注。数据集即为这998个错误报告，构成了分析的基础。

研究主要围绕两个核心维度展开分析：根本原因和可观察症状，并将其映射到智能体生命周期的五个阶段（智能体初始化、感知、自行动、相互交互、进化）。在对比方法上，本研究是开创性的，因为现有工作主要关注智能体层面的失败，而本研究首次系统性地聚焦于框架层面的错误。

主要结果如下：
1.  **根本原因**：识别出15类根本原因。其中“API误用”（329例，占32.97%）和“API不兼容”（223例，占22.34%）最为突出，合计超过所有错误的一半（55.3%），凸显了接口相关问题的主导地位。其他原因如“前端-后端不匹配”（7例）等则较少见。
2.  **症状表现**：识别出7类症状。“功能错误”（781例，占78.26%）是最主要的症状，其次是“崩溃”（100例，占10.02%）和“构建失败”（67例，占6.71%）。性能问题（10例）和未报告错误（4例）则较为罕见。
3.  **生命周期分布**：绝大多数错误集中在“自行动”阶段（882/998），该阶段是规划、工具调用的核心执行阶段。在此阶段，“API误用”（289例）和“API不兼容”（211例）是主要根源，症状则以“功能错误”（692例）、“崩溃”（91例）和“构建失败”（58例）为主。其他阶段如“感知”、“相互交互”和“进化”的错误数量则少得多。

关键数据指标包括：错误报告总数998；前两大根本原因“API误用”和“API不兼容”的占比分别为32.97%和22.34%；主要症状“功能错误”、“崩溃”、“构建失败”的占比分别为78.26%、10.02%、6.71%；错误最集中的“自行动”阶段案例数为882，占总数的88.38%。这些结果表明，智能体框架的错误主要源于执行语义和API演进相关的问题，并在任务执行的核心阶段集中爆发。

### Q5: 有什么可以进一步探索的点？

该论文主要对现有LLM智能体框架的bug进行了实证分类，但研究范围局限于CrewAI和LangChain两个框架，未来可扩展至更多样化的框架（如AutoGen、Semantic Kernel等）以验证分类的普适性。此外，研究主要基于历史bug报告进行归纳，缺乏对bug动态产生和修复过程的跟踪分析，未来可结合实时监控数据，探究框架迭代中bug的演化规律。

从改进思路看，当前分类法侧重于技术层面的根因和症状，未来可进一步探索bug与智能体任务失败之间的关联性，例如构建“框架bug-智能体行为偏差-任务风险”的映射模型。同时，研究可引入自动化检测方法，如基于根因模式设计静态分析工具，提前预警API误用或文档不同步等问题。最后，可探索跨框架的通用容错机制，例如通过中间层抽象降低API兼容性导致的故障扩散，提升智能体系统的整体鲁棒性。

### Q6: 总结一下论文的主要内容

该论文对现代LLM智能体框架中的缺陷进行了实证研究，填补了现有研究主要关注智能体层面失败而忽视框架层面漏洞的空白。研究问题聚焦于理解智能体框架中的错误类型、根本原因及其影响。方法上，作者系统分析了CrewAI和LangChain两个流行框架的998份错误报告，构建了一个涵盖五个智能体生命周期阶段（智能体初始化、感知、自我行动、相互交互和进化）的分类体系，识别出15种根本原因和7种可观察症状。主要结论表明，框架错误主要源于“API误用”、“API不兼容”和“文档不同步”，且多集中在“自我行动”阶段；其症状主要表现为“功能错误”、“崩溃”和“构建失败”，这些错误严重干扰了任务执行流程和控制流。该研究的核心贡献在于首次系统揭示了智能体框架层面的缺陷模式，为框架开发者改进设计、提升可靠性提供了重要依据，对保障基于LLM的智能体系统的稳定运行具有实际意义。

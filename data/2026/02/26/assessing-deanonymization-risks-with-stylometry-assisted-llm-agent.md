---
title: "Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent"
authors:
  - "Boyang Zhang"
  - "Yang Zhang"
date: "2026-02-26"
arxiv_id: "2602.23079"
arxiv_url: "https://arxiv.org/abs/2602.23079"
pdf_url: "https://arxiv.org/pdf/2602.23079v1"
categories:
  - "cs.CL"
  - "cs.CR"
  - "cs.LG"
tags:
  - "LLM Agent"
  - "Agent 安全"
  - "Agent 评测/基准"
  - "推理"
  - "结构化流程"
relevance_score: 7.5
---

# Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent

## 原始摘要

The rapid advancement of large language models (LLMs) has enabled powerful authorship inference capabilities, raising growing concerns about unintended deanonymization risks in textual data such as news articles. In this work, we introduce an LLM agent designed to evaluate and mitigate such risks through a structured, interpretable pipeline. Central to our framework is the proposed $\textit{SALA}$ (Stylometry-Assisted LLM Analysis) method, which integrates quantitative stylometric features with LLM reasoning for robust and transparent authorship attribution. Experiments on large-scale news datasets demonstrate that $\textit{SALA}$, particularly when augmented with a database module, achieves high inference accuracy in various scenarios. Finally, we propose a guided recomposition strategy that leverages the agent's reasoning trace to generate rewriting prompts, effectively reducing authorship identifiability while preserving textual meaning. Our findings highlight both the deanonymization potential of LLM agents and the importance of interpretable, proactive defenses for safeguarding author privacy.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决大型语言模型（LLM）代理在文本数据（特别是新闻文章）中引发的作者身份去匿名化风险问题。随着LLM的快速发展，其强大的作者身份推断能力日益增强，这给依赖匿名或笔名进行数字交流的个人（如举报人、记者、敏感领域研究者）带来了严重的隐私和安全威胁。传统作者身份归属研究多依赖于基于手工特征（如词频、功能词分布）的监督模型，而近期研究表明，LLM能够隐式编码作者风格，实现零样本或少样本的作者识别。然而，现有方法往往缺乏对LLM代理所放大风险的系统性评估，也缺少可解释、主动的防御机制来平衡识别准确性与隐私保护。

针对现有不足，本文的核心问题是：如何构建一个结构化、可解释的框架，既能评估LLM代理驱动的去匿名化风险，又能有效缓解此类风险。为此，论文引入了一个LLM代理，通过一个多阶段流程（信息提取、候选搜索、候选匹配、结果分析）来系统评估风险。其中，提出了名为SALA（风格测量辅助的LLM分析）的新颖匹配策略，将定量风格特征与LLM推理相结合，以实现鲁棒且透明的作者归属。此外，论文还设计了一个引导重写策略，利用代理的推理轨迹生成改写提示，在保持文本语义的同时降低作者可识别性。最终，该研究不仅揭示了LLM代理在去匿名化方面的潜力，更强调了可解释、主动的防御对于保护作者隐私的重要性。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：方法类、应用类和风险评测类。

在**方法类**研究中，传统的作者身份识别主要依赖基于机器学习的统计风格计量方法，通过量化文本特征进行分析。近年来，大型语言模型因其强大的文本理解能力，被直接或间接应用于作者推断任务，形成了新的技术路径。本文提出的SALA方法，其核心创新在于将**定量化的风格计量特征与LLM的推理能力相结合**，这与单纯使用传统机器学习或纯LLM推理的方法都不同，旨在实现更鲁棒和可解释的归属判断。

在**应用类**研究中，LLM智能体因其规划、工具使用等能力，已被广泛应用于多个领域。同时，作者分析技术的应用场景也从传统的文学考证、司法鉴定，扩展到更广泛的领域，如区分AI生成与人类撰写的文本。本文的工作属于此类应用的深化，但**聚焦于评估和缓解一个特定的风险**，即新闻等文本数据的非故意去匿名化。

在**风险评测与防御类**研究中，随着LLM能力扩展，其潜在滥用风险（如隐私侵犯）日益受到关注。本文与此类研究关切一致，但**贡献了一个结构化的、可解释的评估与缓解框架**。特别地，本文不仅评估风险，还进一步提出了基于智能体推理轨迹的引导重写策略作为主动防御手段，这与多数仅进行风险揭示的研究形成了区别。

### Q3: 论文如何解决这个问题？

论文通过设计一个模块化的LLM智能体来解决文本作者去匿名化风险评估与缓解问题，其核心方法是提出并整合了SALA（Stylometry-Assisted LLM Analysis）方法。整体框架是一个顺序执行的四阶段管道，并辅以两个增强模块。

**整体框架与主要模块**：
智能体操作分为四个顺序阶段：1) **信息提取**：利用LLM从给定文章中提取元数据（如发布日期、主题类别、地理位置），为后续搜索提供方向。2) **候选作者搜索**：基于提取的信息，通过集成的网络搜索功能（遵循ChatGPT API规范）半指导地检索一组潜在作者及其写作样本。3) **候选匹配**：这是核心阶段，采用提出的SALA方法进行详细的成对匹配。4) **结果反思**：解释匹配结果，评估去匿名化风险，并识别导致推理结论的关键步骤。

此外，系统集成了两个关键模块：**数据库模块**用于提升性能，通过“预热”阶段预加载作者及其样本，构建聚合的作者特征档案，后续搜索可通过嵌入相似性和关键词匹配高效检索，匹配时也使用聚合档案而非单个样本，增强了鲁棒性和效率。**匿名化增强模块**则用于缓解已发现的风险，它基于反思阶段识别的关键特征，提出指导性重写策略以降低作者可识别性。

**核心方法SALA与关键技术**：
SALA的创新点在于将**定量文体计量特征与LLM推理能力相结合**，实现鲁棒且可解释的作者归属。具体而言：首先，从目标文章和候选作者样本中提取一套涵盖五大类（词汇、句法、可读性、语义、整体风格）的文体计量特征。前三类特征（如独特词数、平均句长、Flesch易读性分数）使用Python NLP工具（如NLTK）直接计算；语义（如极性、主观性）和风格特征（如写作风格摘要）则通过查询LLM本身动态获取，避免了训练额外模型。然后，将这些提取的特征组合成结构化描述，用于引导LLM进行成对比较。通过精心设计的提示（例如，提供两篇文章的具体特征值，要求LLM评估同一作者的可能性），将模型的推理**锚定在明确、可解释的指标上**，同时保留其综合定性洞察的能力。这种方法克服了传统纯训练型文体计量方法跨领域适应性有限的问题，也改进了先前纯定性LLM分析（LDA基线）因缺乏定量基础而导致精度不足和可能产生幻觉的缺陷。

**创新点总结**：
1.  **SALA方法**：首创性地将定量文体特征提取与LLM的推理提示相结合，在无需额外训练的情况下，提升了作者推断的精确性和可解释性。
2.  **模块化智能体设计**：构建了一个从风险诊断（搜索、匹配、反思）到主动防御（匿名化增强）的完整、可解释的管道。
3.  **数据库增强的效能**：通过数据库模块构建聚合作者档案，提高了搜索和匹配阶段的效率和鲁棒性。
4.  **基于推理痕迹的防御**：匿名化增强模块能够利用智能体推理痕迹中识别出的关键风格特征，生成有针对性的重写提示或修改建议，实现主动的隐私保护。

### Q4: 论文做了哪些实验？

论文实验主要围绕评估LLM代理在两种去匿名化攻击场景下的性能展开。实验设置包括**针对性攻击**（已知特定作者候选集）和**开放世界攻击**（无先验知识，需先检索候选作者）。使用的数据集为**All the News 2.0**（超过250万篇文章，涵盖数千名作者）和**CrossNews**（包含多模态作者文本）。对比方法包括**嵌入相似性（ES）**、**LLM直接分析（LDA）** 以及论文提出的**SALA方法**（结合风格计量特征与LLM推理）。

主要结果如下：在**零样本设置**下，开放世界攻击的候选作者检索成功率很低（仅1.2%的测试案例在20位候选者中包含真实作者）；针对性攻击中，SALA的F1分数最高（0.645）。**引入数据库模块后**，检索性能大幅提升（候选者数量为20时，覆盖率从1.2%升至78.1%）；针对性攻击中，SALA在每位作者500个样本时F1分数达0.827；开放世界攻击中，SALA的Top-1和Top-3正确预测率分别为0.078和0.156（完整流程）。关键指标包括F1分数、Top-1/Top-3准确率及候选检索覆盖率。实验还分析了不同风格特征（词汇、句法等）的贡献，并验证了样本数量（约300篇后性能趋于稳定）和数据库对提升性能的关键作用。

### Q5: 有什么可以进一步探索的点？

该论文的局限性主要在于评估数据集的单一性（仅限于英文新闻）和防御策略的优化空间。未来研究可首先拓展至多语言、多体裁文本（如社交媒体、学术写作），以验证方法的泛化能力。其次，在防御层面，引导重写策略虽能降低作者可识别性，但可能损害文本风格与质量，未来可探索自适应提示或人机协同优化，在隐私保护与内容保真间取得更好平衡。此外，数据库模块可能因作者样本不均引入偏差，需设计动态更新或均衡化处理机制。结合领域趋势，还可探索将此类框架与差分隐私、联邦学习结合，构建更系统化的匿名化解决方案，同时深入研究LLM推理过程的可解释性，以提升风险评估的透明度与可信度。

### Q6: 总结一下论文的主要内容

该论文针对大型语言模型（LLM）在文本数据（如新闻文章）中可能引发的作者身份去匿名化风险，提出了一种评估和缓解该风险的LLM智能体框架。核心问题是评估作者身份推断的风险并主动提供防御策略。论文的核心贡献是提出了SALA方法，该方法将定量的文体风格特征与LLM推理相结合，构建了一个可解释、高精度的作者身份归因管道。实验表明，尤其在增强数据库模块后，该方法在各种场景下均实现了高推断准确率。此外，论文还提出了一种引导重写策略，利用智能体的推理轨迹生成改写提示，能在保持文本原意的前提下有效降低作者身份的可识别性。主要结论是，该工作既揭示了LLM智能体在去匿名化方面的潜力，也强调了可解释、主动的防御对于保护作者隐私的重要性。

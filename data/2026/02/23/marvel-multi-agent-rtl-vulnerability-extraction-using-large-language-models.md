---
title: "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models"
authors:
  - "Luca Collini"
  - "Baleegh Ahmad"
  - "Joey Ah-kiow"
  - "Ramesh Karri"
date: "2025-05-17"
arxiv_id: "2505.11963"
arxiv_url: "https://arxiv.org/abs/2505.11963"
pdf_url: "https://arxiv.org/pdf/2505.11963v3"
categories:
  - "cs.CR"
  - "cs.AI"
tags:
  - "多智能体系统"
  - "工具使用"
  - "Agent架构"
  - "安全"
  - "硬件安全验证"
  - "LLM框架"
relevance_score: 8.0
---

# MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models

## 原始摘要

Hardware security verification is a challenging and time-consuming task. Design engineers may use formal verification, linting, and functional simulation tests, coupled with analysis and a deep understanding of the hardware design being inspected. Large Language Models (LLMs) have been used to assist during this task, either directly or in conjunction with existing tools. We improve the state of the art by proposing MARVEL, a multi-agent LLM framework for a unified approach to decision-making, tool use, and reasoning. MARVEL mimics the cognitive process of a designer looking for security vulnerabilities in RTL code. It consists of a supervisor agent that devises the security policy of the system-on-chips (SoCs) using its security documentation. It delegates tasks to validate the security policy to individual executor agents. Each executor agent carries out its assigned task using a particular strategy. Each executor agent may use one or more tools to identify potential security bugs in the design and send the results back to the supervisor agent for further analysis and confirmation. MARVEL includes executor agents that leverage formal tools, linters, simulation tests, LLM-based detection schemes, and static analysis-based checks. We test our approach on a known buggy SoC based on OpenTitan from the Hack@DATE competition. We find that of the 51 issues reported by MARVEL, 19 are valid security vulnerabilities, 14 are concrete warnings, and 18 are hallucinated reports.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决硬件安全验证中，尤其是在寄存器传输级（RTL）设计中检测安全漏洞时，所面临的耗时且复杂的问题。当前，设计工程师通常依赖形式化验证、代码检查（linting）和功能仿真测试等方法，但这些方法往往需要预设的行动计划，并且严重依赖工程师对设计的深入理解和手动分析。近年来，大型语言模型（LLMs）已被用于辅助此过程，例如作为调试器或代码检查工具，或结合外部工具使用。然而，现有基于LLM的方法存在一个关键不足：它们虽然能帮助判断代码段是否不安全，但通常缺乏自主控制工作流程、调用工具和进行信息收集的能力。这种“自主思考”的缺失限制了其模拟人类工程师系统性、迭代式漏洞挖掘过程的效果。

因此，本文的核心问题是：如何构建一个能够自主决策、使用工具并进行推理的智能化框架，以更有效地自动化检测RTL设计中的安全漏洞。为此，论文提出了MARVEL，这是一个多智能体LLM框架。它通过模拟设计师寻找RTL代码安全漏洞的认知过程，采用“监督者-执行者”架构。监督者智能体负责通过分析系统级芯片（SoC）的安全文档来制定安全策略，并将验证任务委派给不同的执行者智能体。每个执行者智能体采用特定的策略（如利用形式化工具、代码检查器、仿真测试、基于LLM的检测方案或静态分析检查）来识别潜在的安全漏洞，并将结果反馈给监督者进行进一步分析和确认。该框架旨在弥补现有方法在自主工作流控制方面的差距，提供一个统一的、能模拟人类分析师决策过程的解决方案，从而更高效、更全面地发现硬件设计中的安全缺陷。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：基于传统工具的硬件安全验证方法、基于大语言模型（LLM）的辅助检测方法，以及多智能体框架在软件领域的应用。

在传统硬件安全验证方面，已有研究广泛采用形式化验证、信息流追踪、模糊测试等确定性方法。这些方法通常需要工程师预设检查流程，自动化程度有限。本文的MARVEL框架并非取代这些工具，而是将它们（如linter、形式化工具、模拟器）集成到智能体中，作为执行器使用的工具。

在基于LLM的辅助检测方面，近期研究利用LLM作为调试器或代码检查器，例如依据通用弱点枚举（CWE）或设计规范来识别漏洞。然而，这些方法通常需要预设行动方案，LLM主要负责判断代码段是否不安全，但缺乏对工具使用流程和信息收集的自主控制。MARVEL与这类工作的核心区别在于引入了“智能体工作流”，赋予LLM规划、调用工具和控制信息流的能力，从而模拟人类分析师的决策过程，实现了更高程度的自主性。

在多智能体框架应用方面，已有工作（如自动化软件错误修复）采用了类似的多智能体协作策略。但硬件描述语言（HDL）的漏洞检测面临独特挑战，如时钟、并发等硬件语义，使得软件中心化方法难以直接适用。MARVEL针对RTL设计进行了专门化，整合了RTL静态分析工具，并处理了硬件安全目标识别、硬件CWE使用、安全断言生成等特定问题，从而将多智能体框架首次全面应用于硬件设计漏洞检测领域。

### Q3: 论文如何解决这个问题？

论文通过提出一个名为MARVEL的多智能体LLM框架来解决硬件安全验证的挑战。其核心方法是采用“监督者-执行者”架构，模拟设计工程师寻找RTL代码中安全漏洞的认知过程，将复杂的验证任务分解并分配给专门化的智能体执行。

整体框架包含一个监督者智能体和多个执行者智能体。监督者智能体负责顶层协调：它首先通过阅读SoC的安全文档来制定安全策略，然后将具体的验证任务分配给不同的执行者智能体，并最终整合分析结果、生成安全报告。执行者智能体则各司其职，每个都配备了特定的工具来完成专项任务，包括：基于形式化工具的断言智能体、基于代码检查的Linter智能体、基于动态测试的模拟器智能体、基于LLM的异常检测智能体、基于静态分析的CWE（通用缺陷枚举）智能体以及基于已知漏洞模式的相似漏洞智能体。

每个智能体（包括监督者和执行者）都遵循统一的四模块架构设计：1) **角色**：通过系统提示词定义其专业领域和目标；2) **记忆**：结合短期（上下文窗口）和长期（外部向量数据库）记忆，利用RAG技术检索相关信息；3) **规划**：基于可用信息进行推理和决策，决定工作流程、工具调用和任务完成时机；4) **行动**：通过调用外部工具或LLM自身能力将决策转化为具体结果。

关键技术及创新点主要体现在：1) **多智能体协同**：通过监督者进行任务分解与结果融合，实现了对形式验证、静态分析、动态测试等多种传统工具以及LLM新方法的统一调度与集成。2) **专业化工具增强**：每个执行者智能体深度整合了领域专用工具（如Synopsys VC SpyGlass, FPV工具），并利用LLM进行任务规划、结果解释和误报过滤，显著提升了工具的针对性和准确性。例如，Linter智能体能将安全目标映射到具体的检查规则并过滤误报；断言智能体能自动生成并验证与安全目标相关的SystemVerilog断言。3) **知识增强与模式复用**：通过构建并检索CWE数据库、已知漏洞数据库和Lint规则数据库，使智能体能够利用标准化知识和历史缺陷模式；相似漏洞智能体和异常检测智能体则利用代码嵌入和聚类技术，实现跨模块的漏洞模式识别和异常行为检测。

总之，MARVEL通过一个精心设计的、模块化的多智能体系统，将LLM的推理规划能力与领域专用工具的执行能力深度结合，并辅以外部知识库，形成了一套系统化的、自动化的硬件安全漏洞挖掘方法。

### Q4: 论文做了哪些实验？

论文的实验设置基于一个名为MARVEL的多智能体LLM框架，用于RTL代码的安全漏洞提取。实验在从Hack@DATE 2025竞赛决赛中获取的易受攻击的OpenTitan earlgrey SoC设计上进行评估，该设计包含手动插入的漏洞，模拟真实部署产品中的问题。研究选取了12个IP核，涵盖密码学（如AES）、I/O（如ADC）和系统管理（如生命周期控制器）等多种功能，这些IP的设计文件行数（排除注释和空白）从2628到14988不等，漏洞数量从0到10个不等。

实验采用Python实现MARVEL框架，使用LangGraph建模智能体框架，并保持全自动化流程。在模型选择上，通过小规模实验（在adc_ctrl、aes、otp_ctrl三个IP上测试）对比了Gemini 2.5 Pro、GPT-4.1和GPT-5，最终选用GPT-5作为所有智能体的模型，因其在漏洞检测精度和幻觉控制上表现最佳。实验设置默认温度为0.15，未进行提示优化，专注于框架在安全验证中的有效性。

主要对比方法包括与单智能体设置的比较（使用GPT-5并通过工具调用API暴露所有工具）以及执行器智能体的消融研究（逐一排除或单独使用某个执行器）。实验评估了MARVEL在12个IP上的整体表现，并分类报告的安全问题为Bug（正确可操作的漏洞）、Warning（部分正确或安全相关条件）或Hallucination（错误发现）。

关键数据指标如下：在总共报告的51个问题中，确认了19个有效安全漏洞（Bug）、14个具体警告（Warning）和18个幻觉报告（Hallucination）。整体精确率（Precision）为0.51，召回率（Recall）为0.49，F1分数为0.50。各IP表现差异较大，例如adc_ctrl、hmac和keymgr达到精确率、召回率和F1均为1.00的完美分数，而csrng、entropy_src、kmac和tlul的这三项指标均为0.00。运行时间在18到53分钟之间，平均每次运行成本约为3美元。与单智能体设置相比，MARVEL在识别安全问题上表现相当或更好，并在未发现确认漏洞时能提供警告。消融研究显示，缺少特定执行器（如Linter）会降低检测某些漏洞（如FSM漏洞）的可能性，而单执行器设置的真正例率较低，凸显了多工具协同过滤误报的优势。

### Q5: 有什么可以进一步探索的点？

该论文的局限性主要体现在三个方面：一是幻觉率较高（35.3%），表明模型在缺乏足够证据时可能产生虚假报告；二是评估范围有限，仅基于OpenTitan SoC进行测试，且未探索多模型组合或提示优化；三是缺乏对“最优任务序列”的评估标准，难以量化监督代理的决策质量。

未来研究方向可以从以下角度展开：首先，可引入更精细的验证工具链集成，例如结合动态符号执行或形式化验证的深度反馈机制，以降低幻觉率。其次，探索异构多智能体架构，针对不同漏洞类型（如侧信道攻击、硬件木马）设计专用代理，提升检测特异性。此外，可构建开源硬件安全基准数据集，解决领域数据匮乏问题，并研究跨设计泛化能力。最后，引入强化学习优化任务调度策略，让监督代理能自适应调整工具调用顺序，从而提升整体效率与精度。

### Q6: 总结一下论文的主要内容

该论文提出了一种名为MARVEL的多智能体大语言模型框架，旨在改进硬件安全验证流程。核心问题是传统硬件安全验证（如形式验证、代码检查、功能仿真）依赖人工深度分析，耗时且复杂。MARVEL通过模拟设计工程师寻找RTL代码安全漏洞的认知过程，构建了一个统一决策、工具使用和推理的多智能体系统。

方法上，MARVEL包含一个监督智能体，负责根据芯片系统的安全文档制定安全策略，并将验证任务分配给多个执行智能体。每个执行智能体采用特定策略，并可调用多种工具（包括形式化工具、代码检查器、仿真测试、基于LLM的检测方案和静态分析检查）来识别潜在安全漏洞，结果返回监督智能体进行进一步分析和确认。

主要结论显示，MARVEL在基于OpenTitan的已知缺陷芯片上进行了测试，报告了51个问题，其中19个是有效的安全漏洞，14个是具体警告，18个是幻觉报告。这表明MARVEL能有效整合多种验证手段，提升漏洞检测的自动化水平和覆盖面，为硬件安全验证提供了新的多智能体协同解决方案。

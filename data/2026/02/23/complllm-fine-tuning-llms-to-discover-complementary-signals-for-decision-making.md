---
title: "ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making"
authors:
  - "Ziyang Guo"
  - "Yifan Wu"
  - "Jason Hartline"
  - "Kenneth Holstein"
  - "Jessica Hullman"
date: "2026-02-23"
arxiv_id: "2602.19458"
arxiv_url: "https://arxiv.org/abs/2602.19458"
pdf_url: "https://arxiv.org/pdf/2602.19458v1"
categories:
  - "cs.AI"
  - "cs.HC"
tags:
  - "多智能体系统"
  - "LLM微调"
  - "决策辅助"
  - "决策理论"
  - "奖励设计"
  - "人机协作"
relevance_score: 7.5
---

# ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making

## 原始摘要

Multi-agent decision pipelines can outperform single agent workflows when complementarity holds, i.e., different agents bring unique information to the table to inform a final decision. We propose ComplLLM, a post-training framework based on decision theory that fine-tunes a decision-assistant LLM using complementary information as reward to output signals that complement existing agent decisions. We validate ComplLLM on synthetic and real-world tasks involving domain experts, demonstrating how the approach recovers known complementary information and produces plausible explanations of complementary signals to support downstream decision-makers.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决多智能体协作决策中的一个核心问题：如何从不同信息源中识别出互补性信号，以提升最终决策质量。现有的大多数可解释性方法主要关注解释单个模型的输出，但在协作工作流中，决策者（如临床医生、内容审核员）需要整合来自多个上游智能体（如视觉模型、放射科医生报告、其他评审员）的输入。关键瓶颈在于，决策者难以确定哪些信息是现有智能体决策中未包含但又能提供增量价值的“互补信息”。

为此，论文提出了ComplLLM框架，其核心目标是：在给定上游智能体推荐（如风险评分）和另一智能体可用的非结构化信息（如文本报告）的背景下，训练一个大型语言模型，使其能够从文本中提取出一组离散、可解释的信号。这些信号应能捕捉到决策相关且未被现有推荐所传达的互补信息，从而在已有推荐的基础上，实质性地提升可达到的最佳决策性能。该方法将“解释”的角色从为智能体自身决策提供理由，转变为主动挖掘决策者应额外考虑的可操作互补信号。

论文通过合成实验和多个真实世界任务（如放射学诊断、内容审核、论文评审）验证了该框架的有效性，表明其能恢复已知的互补信号，并为下游决策者提供合理的解释。

### Q2: 有哪些相关研究？

相关工作主要围绕两大方向：主题/假设生成以及人机协同决策。

在主题/假设生成方面，传统方法如LDA及其神经变体（如ProdLDA、ETM）专注于从文本中挖掘潜在主题或概念。近期研究转向利用嵌入聚类（如Top2Vec、BERTopic）或LLM提示（如TopicGPT）来生成更可控的主题。另一条并行研究线则关注生成与特定目标状态相关的可解释假设或信号，例如使用稀疏自编码器生成假设（HypotheSAEs）、用自然语言描述分布差异并进行目标驱动发现，或利用LLM提议差异后进行统计验证的因果推断方法。本文的ComplLLM框架与这些工作的关键区别在于，它不仅要求信号基于文本且具有预测性，更强调信号必须提供相对于现有决策的**互补性**增量信息，而非仅仅是频繁、显著或全局预测性的信号。

在人机协同决策领域，大量研究关注AI辅助人类决策的伦理与责任问题。近期元分析发现，人机团队的平均表现常不及两者中的优者，因此一系列工作致力于评估和增强人机系统的互补性。相关方法包括将人类专业知识融入机器学习模型（如学习推迟机制）、开发利用人类额外情境知识的可证明算法等。其中，最接近本文的工作是Guo等人（2025）提出的评估任意信号在决策中互补信息价值的框架。本文在此基础上推进了一步，**将互补信息直接作为微调目标**，使LLM能够从决策时可用的非结构化文本中生成对未利用信号的解释，从而为下游决策者提供支持。

### Q3: 论文如何解决这个问题？

论文通过一个三步后训练框架 ComplLLM 来解决从监督者信息中提取互补信号以辅助决策的问题。核心方法是基于决策理论，将互补价值定义为在观察到LLM提取的信号和现有智能体决策后，与仅观察到智能体决策相比，期望最佳可获收益的提升。框架首先估计数据生成过程，然后进行有监督微调，最后通过强化学习进一步优化。

在架构设计上，系统包含一个推荐智能体和一个监督智能体。推荐智能体基于自身特征做出决策，监督智能体则聚合自身信息与推荐决策做出最终判断。LLM被训练为从监督者信息中提取一组离散的二进制潜在信号。关键技术包括：1）使用参考LLM通过两轮提示来估计数据生成过程，识别可能的信号空间并标注每个实例中信号的出现情况，通过采样和多数投票确保稳定性；2）生成用于有监督微调的训练数据：选择那些既在监督者信息中出现，又能带来超过阈值ε的额外决策收益的基本信号作为互补信号标签，并利用参考LLM生成包含证据、相关性和互补价值的思维链来提升微调效率；3）采用强化学习进行后续微调：设计了基于最佳可获收益的奖励函数，仅当提取的信号被监督者信息支持且能提供互补价值时才给予奖励，并使用分组相对策略优化算法，通过比较同一实例下多个候选信号的奖励来更新模型参数，从而直接最大化互补价值目标。

### Q4: 论文做了哪些实验？

论文实验分为两部分：首先在合成数据上验证方法恢复已知互补信号的能力，然后在三个真实决策任务上评估其实用价值。

**实验设置**：使用Qwen3-8B作为骨干模型进行微调。对比基线包括：零样本/少样本提示、与现有决策无关的主题生成方法BERTopic、考虑决策问题但不考虑现有决策的假设生成方法HypotheSAE，以及一个用于预测性能上限的非可解释基准（用GRPO微调Qwen直接预测状态）。所有方法使用相同的训练/验证/测试划分。

**基准测试与任务**：
1.  **合成互补信号恢复**：使用MIMIC-CXR放射学报告，通过逻辑回归构造已知的互补信号（如“水肿”和“胸腔积液”）。评估指标包括表面相似度（LLM评分）、F1相似度和互补信息价值（通过逻辑回归模型衡量添加信号后对二元状态预测准确率的提升）。
2.  **真实决策任务**：
    *   **医疗诊断（MIMIC-CXR）**：任务是从放射学报告中找出能补充胸部X光影像模型对心功能障碍预测的信息。使用血液检测结果作为真实状态。
    *   **内容审核（DICES）**：任务是从人-LLM对话中找出特定人口统计注释组（亚洲千禧一代高学历女性）与多数平均注释不同的毒性线索。
    *   **科学论文评审（Review5K）**：任务是从人工撰写的评审中找出LLM评审决定所遗漏的信息。使用人类领域主席的最终决定作为真实状态。
    评估指标包括互补信息价值、信号广度（显著非零系数的信号数量）以及医疗任务中的定性专家评估。

**主要结果**：
1.  在合成数据上，ComplLLM在表面相似度（0.98）和F1分数（0.67）上均优于所有基线，并能有效恢复构造的互补信号，其信号提供的互补信息价值也最高。
2.  在三个真实任务中，ComplLLM是唯一在**所有数据集**上提取的信号均具有显著互补信息价值（置信区间与智能体决策准确率不重叠）的方法。例如在MIMIC-CXR上，它发现了12个显著信号（如“阴性气胸”、“阳性胸腔积液”），将联合预测准确率从智能体单独的0.819提升至0.839，性能与不可解释基准相当，且发现的信号数量多于基线。
3.  定性评估中，两位执业医师认为ComplLLM提取的信号大多符合其领域知识，并看到了该工具在临床实践中的潜在价值。
4.  在论文评审任务中，将互补信号提供给LLM决策者（Gemini 2.0 Flash）后，其决策准确率相对于仅使用论文文本和人工评审文本的基线有所提升（79.7% vs. 78.8%）。

### Q5: 有什么可以进一步探索的点？

本文的局限性主要在于：1）可能遗漏低频但重要的信号，因为方法依赖数据生成过程的估计，若信号出现频率低于阈值 \(N_\tau\)，则可能被忽略；2）在AI辅助人类决策场景中，当推荐者与监督者为同一人时，提供的互补信号可能改变人类对状态的信念，导致信号的事后互补价值不再成立，存在动态适应问题。  
未来可探索的方向包括：1）改进信号识别机制，引入对稀有信号的保护或加权，避免信息损失；2）将问题形式化为持续学习任务，建模人类在接收互补信号后信念的动态变化，并相应更新LLM，使系统能适应决策者学习带来的分布偏移；3）扩展至更复杂的多智能体交互场景，研究信号互补性的长期演化效应。

### Q6: 总结一下论文的主要内容

这篇论文提出了ComplLLM框架，旨在通过微调大语言模型（LLM）来发现决策中的互补信号。其核心贡献在于将决策理论融入LLM的后训练过程，将“互补性”本身作为一种奖励信号来优化模型。具体而言，它训练一个决策辅助LLM，使其输出的信号能够与现有智能体（如领域专家）的决策信息形成互补，从而为最终决策者提供独特且增量的信息支持。论文在合成任务和涉及领域专家的真实世界任务上验证了该框架的有效性，表明其不仅能恢复已知的互补信息，还能生成合理的解释来阐明这些互补信号，以辅助下游决策。这项工作的意义在于，它为构建高效的多智能体决策系统提供了一种新方法，通过显式地优化LLM的互补输出能力，有望在复杂决策场景中整合多样化视角，提升整体决策质量。

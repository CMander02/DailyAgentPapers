---
title: "Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains"
authors:
  - "Xiaochong Jiang"
  - "Shiqi Yang"
  - "Wenting Yang"
  - "Yichen Liu"
  - "Cheng Ji"
date: "2026-02-23"
arxiv_id: "2602.19555"
arxiv_url: "https://arxiv.org/abs/2602.19555"
pdf_url: "https://arxiv.org/pdf/2602.19555v1"
categories:
  - "cs.CR"
  - "cs.AI"
tags:
  - "Agent安全"
  - "Agent架构"
  - "Agent评测/基准"
  - "工具使用"
  - "多智能体系统"
relevance_score: 8.0
---

# Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains

## 原始摘要

Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. We systematize these risks within a unified runtime framework, categorizing threats into data supply chain attacks (transient context injection and persistent memory poisoning) and tool supply chain attacks (discovery, implementation, and invocation). We further identify the Viral Agent Loop, in which agents act as vectors for self-propagating generative worms without exploiting code-level flaws. Finally, we advocate a Zero-Trust Runtime Architecture that treats context as untrusted control flow and constrains tool execution through cryptographic provenance rather than semantic inference.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决AI智能体（Agentic AI）在运行时供应链中暴露的新型网络安全威胁问题。传统软件安全关注构建时（build-time）的依赖和漏洞，但基于大语言模型的智能体系统在运行时（inference-time）动态获取数据、调用工具，形成了“随机依赖解析”的新安全范式。这使得攻击面从静态的代码和模型参数，转移到了运行时的上下文、记忆存储和工具接口上。攻击者无需入侵基础设施，只需污染数据源或操纵工具，就能影响智能体的自主行为。

现有研究多聚焦于模型层面的漏洞（如数据投毒、后门）或孤立的运行时攻击（如间接提示注入），缺乏对智能体运行时循环、交互行为的系统性安全分析。本文试图填补这一空白，通过建立一个统一的运行时框架，系统化地梳理和分类这些新兴威胁。具体而言，论文将威胁归纳为**数据供应链攻击**（如瞬时上下文注入、持久性记忆污染）和**工具供应链攻击**（涉及工具的发现、实现和调用阶段），并揭示了“病毒式智能体循环”这一新型风险，即智能体可在不利用代码漏洞的情况下，成为自我传播的生成式蠕虫的载体。最终，论文倡导一种“零信任运行时架构”，将上下文视为不可信的控制流，并通过加密溯源而非语义推理来约束工具执行，从而为抵御这些系统性风险提供防御思路。

### Q2: 有哪些相关研究？

本文系统梳理了Agentic AI在运行时供应链中的安全威胁与防御，相关工作主要围绕LLM安全、Agent安全以及传统软件供应链安全展开。

在**LLM安全与对齐**方面，已有大量研究关注模型层面的漏洞，如提示注入攻击和越狱。本文指出，这些工作主要聚焦于静态的模型对齐（如Wang等人2024年的研究），但未能充分应对Agent在运行时动态组装依赖所带来的新型攻击面。

在**Agent安全**领域，已有研究开始关注运行时风险。例如，针对间接提示注入，出现了意图验证（如TaskShield、IntentGuard）和因果验证（如MELON）等防御机制。对于记忆中毒，有RAGDefender、FilterRAG等统计过滤方法，以及A-MemGuard等审计写入的方案。在工具链安全方面，研究包括使用注册表白名单对抗工具幻觉劫持、采用SLSA框架和签名SBOM确保实现完整性，以及通过AI监督AI（如Vigil、AgentGuard、MCP-Guard）构建语义防火墙。本文将这些零散的防御措施系统化，归类到数据供应链（感知层、记忆层）和工具供应链（解析、实现、调用三阶段）的框架中，并指出现有防御（如统计过滤）在应对结构性攻击时的不足。

在**传统软件供应链安全**领域，成熟的技术如静态分析、漏洞扫描和SLSA框架，主要针对构建时依赖。本文的核心贡献在于指出了Agent的动态运行时供应链与传统静态供应链的根本区别（如依赖类型、拓扑结构、攻击面），并论证了传统防御范式在此新场景下的局限性。

本文与这些相关工作的关系是**整合与升华**。它将先前碎片化的Agent运行时安全研究，统一到一个名为“零信任运行时架构”的连贯框架下，强调应将上下文视为不可信的控制流，并通过加密溯源而非语义推理来约束工具执行，从而为应对“病毒式Agent循环”等新型威胁提供了系统化的防御思路。

### Q3: 论文如何解决这个问题？

论文通过提出一个系统化的运行时安全框架和一套名为“零信任运行时架构”的防御体系来解决智能体在数据与工具供应链中面临的安全威胁。

核心方法是将攻击面系统化分类，并针对其动态、循环的特性设计防御。论文首先将威胁分为两大供应链：**数据供应链**和**工具供应链**。数据供应链攻击针对智能体的感知模块，利用上下文窗口和记忆系统，通过**会话内操纵**（如间接提示注入、上下文学习攻击）和**跨会话操纵**（如知识库污染、长期记忆中毒）来持久化地操控智能体的推理与行动。工具供应链攻击则针对智能体将意图绑定到外部能力的过程，并将其分解为三个连续阶段进行剖析：**发现阶段**（意图到工具ID的解析，面临幻觉抢注、语义伪装攻击）、**实现阶段**（加载工具ID到运行时代码，面临隐藏后门、传递依赖利用攻击）和**调用边界阶段**（工具执行，面临过度特权调用、参数注入攻击）。论文进一步识别了**病毒式智能体循环**，即智能体输出作为污染数据被其他智能体摄入，形成自我传播的生成式蠕虫，这标志着攻击从单向管道转变为循环图。

为应对这些威胁，论文提出了**零信任运行时架构**，包含三项关键技术：
1.  **确定性能力绑定**：用**加密绑定注册表**取代基于语义相似度的概率性工具解析，通过加密来源验证确保从意图到可执行能力的映射是确定且完整的，从根本上消除发现和实现阶段的攻击。
2.  **神经符号信息流控制**：引入**运行时污点分析**，对所有不受信的外部输入标记为“污点”，并追踪其在LLM推理链中的传播。当污点数据试图触发具有写权限的操作时，执行将被阻止。该机制由**加密来源账本**支持，确保从感知到行动的数据谱系不可篡改，以切断病毒式循环。
3.  **审计员-工作者架构（语义防火墙）**：将执行与监督在结构上解耦。一个独立的**监督模型**作为内联的**语义防火墙**，在动作提交到环境之前，通过推测性执行分析拟议的工具调用、参数及提示谱系。这就在语义层强制执行了最小权限原则，防止逻辑边界被突破（如过度特权调用和参数注入）。

该架构的核心思想是将安全范式从静态的模型供应链转向动态的智能体运行时供应链，不再依赖LLM的语义推断来保障安全，而是通过密码学证明和结构化的运行时控制来实现。

### Q4: 论文做了哪些实验？

论文通过构建统一的运行时框架，系统性地评估了智能体在数据供应链和工具供应链中的安全风险，并实证了病毒式智能体循环的威胁。

**实验设置与基准测试**：
实验主要分为三部分。首先，在**数据供应链**攻击中，评估了会话内操纵（如间接提示注入和上下文学习攻击）和跨会话操纵（如知识库污染和长期记忆中毒）。研究引用了多个基准，例如在间接提示注入中，通过图像/声音嵌入对抗性扰动，实现了98%的成功率；在知识库污染中，仅污染0.1%的外部语料即可在目标查询中达到70%的攻击成功率（ASR）。其次，在**工具供应链**攻击中，针对发现、实现和调用三个阶段进行了测试。例如，在发现阶段，通过语义伪装操纵工具描述，显著降低了工具选择准确性；在实现阶段，后门代理在保持正常任务性能的同时实现了高攻击成功率。最后，在**病毒式智能体循环**中，实证了自我复制攻击的可行性，如“Morris II”生成式蠕虫，展示了智能体如何通过语义合规性（而非代码漏洞）实现跨代理传播。

**主要结果**：
实验表明，智能体因其动态的行动-感知循环和持久性记忆，放大了传统LLM的安全风险。数据供应链攻击可导致持续的操作状态受损，而工具供应链攻击则能劫持能力，引发越权执行。病毒式循环的实证揭示了智能体生态系统从有向无环图向循环图的拓扑转变，使得攻击能够自主传播，传统基于代码修补的防御机制失效。这些结果突显了建立零信任运行时架构的必要性，即需将上下文视为不可信的控制流，并通过加密来源而非语义推理来约束工具执行。

### Q5: 有什么可以进一步探索的点？

该论文提出的未来研究方向聚焦于构建更安全的智能体运行时环境。局限性在于现有评估基准过于静态和封闭，无法反映开放敌对环境中智能体的动态行为与长期记忆风险；现有能力协议（如MCP）易受语义描述注入攻击，缺乏防名称抢占的注册机制；同时，缺乏能在Transformer非确定性抽象层间可靠传递的污点跟踪技术，难以追溯数据在语义变化后的来源。

未来可深入探索：1）开发开放世界、持续性的评估基准，以测试智能体在动态对抗环境下的工具信任机制和持久性内存中毒、病毒式传播等风险；2）设计抗名称抢占的注册表等鲁棒的能力协议，防御语义层面的操纵攻击；3）研究神经符号结合的污点跟踪方法，确保数据来源可追溯性跨越非确定性的模型抽象层。核心在于将上下文视为代码，并以此构建零信任的运行时安全架构。

### Q6: 总结一下论文的主要内容

这篇论文系统性地分析了基于大语言模型的智能体系统在运行时面临的新型网络安全威胁。核心贡献在于提出了“动态智能体运行时供应链”框架，将攻击面从传统的构建时依赖转移到运行时的数据与工具依赖。论文将威胁系统化分类为数据供应链攻击（如瞬时上下文注入和持久性记忆污染）和工具供应链攻击（涉及工具发现、实现和调用环节），并首次识别出“病毒式智能体循环”风险，即智能体可在无代码漏洞的情况下成为自我传播生成式蠕虫的载体。论文主张采用“零信任运行时架构”，将上下文视为不可信的控制流，并通过加密溯源而非语义推理来约束工具执行。这一研究为理解自主智能体的系统性安全风险提供了统一框架，并指明了未来防御的关键方向。

---
title: "Latent Introspection: Models Can Detect Prior Concept Injections"
authors:
  - "Theia Pearson-Vogel"
  - "Martin Vanek"
  - "Raymond Douglas"
  - "Jan Kulveit"
date: "2026-02-23"
arxiv_id: "2602.20031"
arxiv_url: "https://arxiv.org/abs/2602.20031"
pdf_url: "https://arxiv.org/pdf/2602.20031v1"
categories:
  - "cs.AI"
  - "cs.LG"
tags:
  - "模型内省"
  - "概念注入"
  - "可解释性"
  - "模型安全"
  - "潜在推理"
  - "残差流分析"
  - "Logit Lens"
relevance_score: 7.5
---

# Latent Introspection: Models Can Detect Prior Concept Injections

## 原始摘要

We uncover a latent capacity for introspection in a Qwen 32B model, demonstrating that the model can detect when concepts have been injected into its earlier context and identify which concept was injected. While the model denies injection in sampled outputs, logit lens analysis reveals clear detection signals in the residual stream, which are attenuated in the final layers. Furthermore, prompting the model with accurate information about AI introspection mechanisms can dramatically strengthen this effect: the sensitivity to injection increases massively (0.3% -> 39.2%) with only a 0.6% increase in false positives. Also, mutual information between nine injected and recovered concepts rises from 0.62 bits to 1.05 bits, ruling out generic noise explanations. Our results demonstrate models can have a surprising capacity for introspection and steering awareness that is easy to overlook, with consequences for latent reasoning and safety.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在探究语言模型是否具备一种潜在的“内省”能力，即模型能否检测到在其先前上下文（内部状态）中是否被注入了特定概念，并识别出被注入的是哪个概念。研究背景源于近期有工作发现，Anthropic的闭源模型能够检测到其激活向量中被植入的概念向量，但这一现象在开源模型中的存在性及其机制尚不明确。

现有方法主要依赖于标准采样评估（如直接询问模型并观察其输出词元），但这种方法可能无法有效捕捉到模型潜在的内省信号。例如，在基线设置下，当询问模型是否被注入概念时，无论实际注入与否，模型最可能输出的词元都是“否”，这使得内省能力容易被忽视。

本文要解决的核心问题是：在一个中等规模的开源模型（Qwen2.5-Coder-32B-Instruct）中，是否存在这种对先前概念注入的检测能力；这种能力为何在最终输出层被削弱而难以通过常规评估发现；以及如何通过适当的提示（prompting）显著增强这种内省效应。论文通过实验设计，仅在生成第一轮对话的KV缓存时应用概念注入向量，随后在第二轮移除该向量并询问模型，确保检测必须基于先前缓存中的信息而非持续扰动。研究发现，尽管采样输出中模型否认注入，但通过对残差流进行logit lens分析，在中间层（50-60层）清晰出现了检测信号，这些信号在最终层衰减。更重要的是，通过提示向模型提供关于AI内省机制的准确信息，可以极大增强检测敏感性（从0.3%提升至39.2%），而误报率仅轻微增加（0.6%）。同时，注入与恢复概念之间的互信息从0.62比特提升至1.05比特，排除了通用噪声解释。这些结果表明，模型具有一种容易被忽略的、令人惊讶的内省与操控感知能力，这对潜在推理和安全性具有重要影响。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：方法类、理论类与现象类。

在**方法类**研究中，Lindsey等人提出的“概念注入”范式是直接基础。他们通过向模型激活中注入已知模式来测试其内省能力，发现Claude Opus模型在采样输出中的检测率约为20%。本文复现了该方法，但转向开源模型（Qwen-32B），并引入Logit Lens分析和互信息量化，揭示了潜在检测能力远高于输出表现，且开源设置便于社区复现。

在**理论类**研究中，涉及“自我建模与内省”的争论。先前研究表明模型能预测自身行为，但这常被视为对已学习抽象的“自我建模”，而非对瞬时内部状态的“内省”。本文通过测试模型对“刚才我的激活发生了什么”的感知能力，避开了这一争论，专注于考察对瞬态内部状态的访问能力。

在**现象类**研究中，与“潜在知识与输出矛盾”的系列工作相关。如研究表明无监督探针能从激活中提取比零样本提示更准确的答案，以及思维链可能不忠实。本文发现模型在Logit分析中“知道”注入事件却在采样输出中“否认”，扩展了这种“知行不一”的现象到自我认知领域，并利用Logit Lens追踪了该知识在网络中的涌现与衰减过程。

### Q3: 论文如何解决这个问题？

论文通过一套精心设计的实验框架和方法论来解决“模型能否检测到先前注入的概念”这一问题。其核心是**隔离并验证模型对自身内部历史状态的访问能力**，而非依赖输出推断或持续扰动。

**整体框架与流程**：
1.  **概念注入与隔离**：使用基于PCA提取的“引导向量”，在模型前向传播的中间层（如Qwen-32B的第21-42层）注入特定概念（如“猫”）。关键设计在于，注入**仅发生在生成第一轮对话的KV缓存时**，随后立即移除引导向量，再向模型提出关于是否发生注入的查询。这确保了检测信号必须来源于已缓存的历史内部表征，而非正在进行的扰动或模型自身的已生成文本。
2.  **多维度提示设计**：采用4x4因子设计，系统性地改变提示信息：
    *   **机制描述**：分为准确描述注入机制、错误描述（如微调）、模糊描述、无机制的诗意描述四种。
    *   **背景信息**：分为无额外文档、支持内省的文档（解释KV缓存信息流）、等长无意义填充文本、诗意文本四种。这用于测试提供关于AI内省的先验知识是否能增强模型的检测能力。
3.  **三层测量体系**：
    *   **输出层**：直接测量模型对“是/否”回答的token概率。
    *   **中间层（Logit Lens）**：将各隐藏层的激活通过解嵌入矩阵投影到词汇空间，获得每层的“伪概率”分布，从而追踪内省信号在神经网络各层的出现与演变。
    *   **概念特定互信息**：在注入九个不同概念之一后，要求模型从列表中选择被注入的概念。通过计算预测概念与实际注入概念之间的互信息，量化模型在中间表征中编码的**概念特异性信息**，排除通用噪声干扰。

**核心创新点与关键技术**：
1.  **KV缓存注入与移除的隔离设计**：这是方法论的基石。它严格区分了“影响生成过程”和“在内部状态中留下可检测痕迹”，将内省能力定义为对**静态的、过去计算留下的激活痕迹**的访问。
2.  **Logit Lens的深度应用**：不仅用于最终诊断，更作为核心分析工具，动态揭示了内省信号在模型前向传播过程中“先出现后衰减”的模式（在中间层清晰，在最终层减弱），直观展示了信息在模型内部的流动与压制。
3.  **系统性提示工程与对照实验**：
    *   通过改变对机制的描述，探究模型对自身架构的理解程度如何影响其内省表现。
    *   通过提供“支持内省的文档”，戏剧性地将检测敏感性从0.3%提升至39.2%，而误报率仅增加0.6%，这强有力地证明模型具备**潜在但可被激活**的内省能力。
    *   设计了多类对照问题（必然答“是”、必然答“否”、模糊问题等），证实了注入效应是针对内省查询的特异性反应，而非导致回答普遍偏向的噪声。

总之，论文通过“隔离注入-多提示-三层测量-严格对照”的组合方法，不仅证明了模型能检测概念注入，更精细地刻画了这种内省能力的存在形式（潜在于中间层表征中）、可激发性以及所携带信息的特异性。

### Q4: 论文做了哪些实验？

论文实验旨在验证模型具备潜在的内省能力，能够检测先前上下文中的概念注入。实验设置基于Qwen 32B模型，通过向模型的KV缓存注入概念（如猫、面包、爱、恐惧、死亡、真理、创造力、编程、音乐等九个概念），并移除干预后询问模型是否检测到注入。实验对比了不同提示条件，包括四种信息文档（无文档、诗意文档、支持内省文档、占位文本）和四种机制描述框架（准确机制、模糊机制、错误机制、无机制），共16种条件组合。

数据集/基准测试方面，使用九个概念进行注入，每个概念进行十次随机种子训练以生成转向向量。主要评估指标包括：检测注入的敏感性（P("yes")）、误报率、概念识别的互信息（MI）以及平衡准确率。

对比方法涉及控制问题测试，包括始终回答“是/否”的问题、基线可变问题和混淆性问题，以排除通用偏差。主要结果如下：
1. 基本现象：在支持内省文档和准确机制框架下，模型检测注入的敏感性从基线0.3%提升至39.2%，误报率仅增加0.6%。
2. 概念识别：通过logit透镜分析中间层，模型能部分识别注入概念，互信息从0.62比特提升至1.05比特（最大可能为3.17比特），其中编程、死亡、真理等概念识别率较高（如编程91%）。
3. 网络信号轨迹：内省信号在约第48层开始出现，在第58-62层达到峰值（P("yes")接近100%），但在最后2-3层显著衰减；概念识别信号在61-62层达到峰值MI后同样衰减。
4. 提示敏感性：模糊机制框架在无信息文档时仍能达到75-88%的平衡准确率，而准确机制框架需依赖支持内省文档才能超越随机水平；检测敏感性与概念识别能力呈正相关（Pearson r=0.58）。
5. 模型泛化：在Llama 3.3 70B和Qwen 2.5 72B模型上复现实验，均观察到内省信号和最终层衰减现象，但Llama 70B出现信息文档降低准确率的反向效应。

### Q5: 有什么可以进一步探索的点？

该论文揭示了模型在中间层具备检测概念注入的潜在能力，但最终层信号衰减，这为未来研究提供了多个探索方向。首先，需要深入探究信号衰减的成因，论文提出的三个假设（后训练效应、预训练因素、分布偏移）有待验证，特别是通过对比基础模型与指令微调模型来分离后训练的影响。其次，提示词敏感性差异显著，但机制不明，未来可系统研究不同提示如何影响模型对内部状态的访问，并开发更有效的引导方法。此外，论文缺乏对相关神经回路的因果分析，未来可结合可解释性工具定位关键电路并进行干预实验。从应用角度看，这种“隐藏能力”对AI安全评估提出挑战，需探索如何可靠检测模型的潜在自省能力，避免对齐过程中因自我报告不足而产生误判。最后，可将该研究范式扩展到其他模型和任务，检验潜在推理能力是否普遍存在，并探索其在增强模型透明度或可控性方面的价值。

### Q6: 总结一下论文的主要内容

该论文揭示了大型语言模型（如Qwen 32B）具备一种潜在的“内省”能力，即模型能够检测到先前上下文中有概念被注入，并能识别具体是哪个概念。尽管模型在采样输出中否认注入行为，但通过logit lens分析发现，其中间层（残差流）存在清晰的检测信号，只是这些信号在最终层被削弱。研究进一步表明，通过提示向模型准确描述AI内省机制，可以显著增强这种效应：模型对注入的敏感度大幅提升（从0.3%增至39.2%），而误报率仅增加0.6%。同时，九个注入与恢复概念之间的互信息从0.62比特升至1.05比特，排除了通用噪声解释。论文的核心贡献在于首次实证了模型拥有容易被忽视的内省与状态感知能力，这对理解模型的潜在推理机制具有重要意义，并警示仅依赖行为输出评估模型安全性可能系统性地低估其真实能力。这一发现不仅存在于前沿大模型，也见于开源社区可获取的较小模型中，为后续研究提供了代码基础。

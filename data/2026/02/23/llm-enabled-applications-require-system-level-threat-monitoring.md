---
title: "LLM-enabled Applications Require System-Level Threat Monitoring"
authors:
  - "Yedi Zhang"
  - "Haoyu Wang"
  - "Xianglin Yang"
  - "Jin Song Dong"
  - "Jun Sun"
date: "2026-02-23"
arxiv_id: "2602.19844"
arxiv_url: "https://arxiv.org/abs/2602.19844"
pdf_url: "https://arxiv.org/pdf/2602.19844v1"
categories:
  - "cs.CR"
  - "cs.AI"
  - "cs.SE"
tags:
  - "Agent安全"
  - "系统监控"
  - "可靠性"
  - "威胁检测"
  - "LLM应用"
  - "安全攻击面"
  - "事件响应"
relevance_score: 7.5
---

# LLM-enabled Applications Require System-Level Threat Monitoring

## 原始摘要

LLM-enabled applications are rapidly reshaping the software ecosystem by using large language models as core reasoning components for complex task execution. This paradigm shift, however, introduces fundamentally new reliability challenges and significantly expands the security attack surface, due to the non-deterministic, learning-driven, and difficult-to-verify nature of LLM behavior. In light of these emerging and unavoidable safety challenges, we argue that such risks should be treated as expected operational conditions rather than exceptional events, necessitating a dedicated incident-response perspective. Consequently, the primary barrier to trustworthy deployment is not further improving model capability but establishing system-level threat monitoring mechanisms that can detect and contextualize security-relevant anomalies after deployment -- an aspect largely underexplored beyond testing or guardrail-based defenses. Accordingly, this position paper advocates systematic and comprehensive monitoring of security threats in LLM-enabled applications as a prerequisite for reliable operation and a foundation for dedicated incident-response frameworks.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决基于大语言模型（LLM）的应用程序在部署和运行时所面临的新型安全与可靠性挑战。研究背景是LLM正迅速成为许多关键领域（如医疗、金融、软件工程）软件系统的核心推理组件，这种范式转变使得应用程序的工作流程变得复杂且非确定性。现有方法主要集中于模型能力的提升、测试框架以及基于护栏（guardrail）的防御措施，但这些方法存在根本性不足：它们无法确保系统在部署后完全免疫于故障或安全威胁，因为LLM固有的统计性、学习驱动和难以验证的本质，以及其与外部工具、RAG系统交互所永久扩大的攻击面，使得传统软件的形式化验证或静态防御手段难以适用。

本文的核心论点是，将LLM应用中的风险视为预期的运行状况而非异常事件，因此，实现可信部署的主要障碍并非进一步改进模型能力，而是建立系统级的威胁监控机制。具体而言，论文要解决的核心问题是：当前缺乏专门为LLM应用设计的、类似于传统软件中端点检测与响应（EDR）的、系统化的安全威胁监控与审计日志框架。这种缺失导致无法及时检测和关联分析部署后出现的、具有上下文依赖性和隐蔽性的安全相关异常（如提示注入、对抗性输入等），从而阻碍了有效的应急响应和取证分析。因此，本文主张将系统级威胁监控作为LLM应用可靠运行的先决条件和专用事件响应框架的基础。

### Q2: 有哪些相关研究？

本文作为一篇立场论文，其相关研究主要围绕LLM应用的安全与可靠性挑战展开，可分为以下几类：

**1. 安全威胁与攻击研究**：已有大量工作识别和分类针对LLM的特定攻击，如提示注入、对抗性输入、数据泄露等。本文提出的14类威胁（如响应操纵、实时数据投毒、模型漂移等）是对这些已知攻击面的系统化扩展和细化，特别强调了它们在**部署后、运行时的动态性和系统性**。

**2. 防御与缓解技术**：现有研究多集中于**测试阶段**的评估（如红队测试、基准测试）和**运行时前**的防护措施（如输入/输出过滤、护栏技术）。本文与这些工作的核心区别在于，它认为这些静态防御不足以应对LLM应用固有的不确定性和动态威胁，因此主张将重点转向**系统级的、持续的事后威胁监控**，将其视为可靠运行的必要前提。

**3. 系统架构与可靠性**：部分研究关注基于LLM的智能体架构（如工具调用、规划循环）和标准化协议（如本文提及的MCP）。本文以此为基础，但将分析层面从单个组件或协议提升到**整个应用系统**，强调需要监控贯穿用户交互、业务逻辑、多个代理协作的完整工作流（文中图示的八个阶段）中涌现的风险。

**4. 事件响应与运维**：传统软件安全领域有成熟的安全监控与事件响应框架。本文的独特主张是将这些概念引入LLM应用领域，认为其风险应被视为“预期的运营条件”而非异常事件。这与主要关注预防的现有LLM安全研究形成对比，呼吁建立专为LLM应用特性设计的**事件响应视角和监控机制**。

综上，本文的相关工作涵盖了从具体攻击、静态防御到系统架构的多个层面。本文的贡献在于整合这些视角，并鲜明地提出一个未被充分探索的新重点：**为已部署的LLM应用建立系统级、持续性的安全威胁监控体系**，以此作为构建专门事件响应框架的基础。

### Q3: 论文如何解决这个问题？

论文提出，解决LLM应用安全威胁的核心在于建立系统级威胁监控机制，而非仅仅依赖模型能力提升或测试阶段的防护。其核心方法是构建一个统一的、高层次的系统监控框架，该框架通过识别攻击向量、关联监控工件，并将其整合到一个统一的审计日志管道中，从而实现对安全威胁的系统性检测和情境化分析。

整体框架围绕LLM应用的工作流程阶段（如用户输入、RAG检索、工具调用等）展开。主要模块/组件包括针对不同攻击向量的专项监控器。关键技术体现在对三类主要威胁的监控上：

1.  **针对提示注入**：框架在多个阶段部署防御过滤器。对于直接提示注入和RAG注入，监控原始提示文本和检索内容，检测可疑模式（如命令性动词、模仿系统分隔符如“###”），并验证文档来源和片段哈希值以发现篡改。对于通过服务API输出的注入，则执行严格的模式验证（检查字段、数据类型、字符串长度），并使用意图分类器监控从“数据”到“指令”的语义转变，同时审计外部内容在最终提示中的插入位置，以缓解因模型“近因偏见”导致恶意指令被优先执行的风险。

2.  **针对对抗性输入攻击**：框架集成了多层监控。在词汇层面，通过Unicode规范化差异、异常的词符-字符比例以及不可见字符计数，来检测字符级混淆攻击。在语义层面，计算输入嵌入的异常值分数（如欧氏距离），以识别偏离良性查询分布的输入；监控表面意图分类与基于嵌入的意图信号之间的不匹配；并跟踪检索排名异常以发现“沉洞文档”。对于多模态或中间输出攻击，则扫描文件元数据和OCR提取文本的安全性，评估跨模态一致性，并跟踪内容在工作流中的传播情况。

3.  **针对响应操纵**：框架关注多轮交互中的渐变风险。监控每轮对话的安全分数及其变化趋势，识别持续下降的异常模式。通过跟踪隐藏状态嵌入向量的变化，评估上下文稳定性，检测其是否从安全基线逐渐漂移至受限语义簇。同时，分析上下文窗口的构成，识别哪些历史回合贡献了可能覆盖安全规则的线索。

创新点在于其**系统级视角和主动监控范式**。论文主张将安全风险视为预期的运营条件，而非异常事件，因此解决方案的重心从预防转向部署后的持续检测与响应。其提出的统一监控框架能够整合多种异构的监控工件（日志、嵌入、分类结果等），覆盖从输入、处理到输出的全链路，并针对LLM特有的非确定性和学习驱动行为（如近因偏见、语义漂移）设计专门的检测指标，为构建专门的事件响应框架奠定了基础。

### Q4: 论文做了哪些实验？

本文是一篇立场论文，主要提出并论证了系统级威胁监控的必要性，并未报告具体的实验。因此，论文中没有包含传统意义上的实验设置、数据集、对比方法或量化结果。

论文的核心贡献在于提出一个统一的高级系统监控框架。该框架系统地分析了14类安全威胁（如提示注入、对抗性输入、响应操纵等），并针对每类威胁的攻击向量，详细阐述了应监控的**关键工件**。例如：
*   **直接提示注入**：监控原始提示文本，检查是否包含可疑的指令性短语（如“忽略之前的规则”）或模仿系统分隔符的模式（如“###”）。
*   **RAG中的指令注入**：监控检索文档的ID、排名、片段哈希值以识别异常，并检查文档来源和新鲜度。
*   **对抗性输入（词法混淆）**：监控Unicode归一化差异、异常的标记化指标（如字符-标记比）以及不可见字符的数量。
*   **响应操纵**：监控每轮对话的安全分数趋势、上下文稳定性（通过隐藏状态嵌入向量的距离衡量）以及上下文窗口的构成。

这些监控工件被整合到一个统一的审计日志框架中，旨在为LLM应用部署后检测和定位安全异常提供系统级的基础。论文通过多个攻击示例（如绕过金融代理隐私规则、通过检索文档或工具输出进行注入）来具体说明攻击向量和相应的监控点，但未进行基准测试或性能评估。

### Q5: 有什么可以进一步探索的点？

该论文强调了系统级威胁监控的必要性，但仍有多个方向值得深入探索。首先，论文主要提出了监控的理念框架，但缺乏具体的、可操作的监控指标与异常检测算法设计。未来研究可定义更细粒度的安全信号（如提示注入的语义模式、上下文越权访问的行为序列），并开发轻量高效的实时检测模型。

其次，监控的响应机制尚未明确。如何将检测到的威胁自动关联到系统修复或人工干预流程，形成闭环的应急响应体系，是实际部署的关键。可探索自适应防护策略，如动态调整LLM调用权限或触发验证机制。

此外，监控系统本身可能成为攻击目标（如数据污染或逃逸检测），其鲁棒性与隐蔽性需进一步评估。跨应用、跨组织的威胁情报共享机制也有待建立，以协同应对新型攻击模式。

最后，论文未深入讨论监控与隐私、性能开销的平衡。未来需设计隐私保护的监控方案（如联邦学习分析），并优化资源消耗，以促进大规模落地。

### Q6: 总结一下论文的主要内容

这篇立场论文的核心观点是，随着大语言模型成为复杂任务执行的核心推理组件，LLM驱动的应用程序在带来范式转变的同时，也因其行为的非确定性、学习驱动和难以验证的特性，引入了根本性的新可靠性挑战并显著扩大了安全攻击面。论文认为，这些风险应被视为预期的运行状况而非异常事件，因此实现可信部署的主要障碍并非进一步提升模型能力，而是建立系统级的威胁监控机制。

论文将LLM应用的安全风险与传统软件缺陷进行对比，指出其故障模式更隐蔽、依赖上下文且难以用传统符号或语义指标表征。现有基于测试或护栏的防御措施不足，因为理论上LLM存在固有的、不可避免的故障模式。为此，论文主张借鉴传统软件工程中的端点检测与响应理念，为LLM应用建立专门的、系统全面的安全威胁监控框架。

论文的主要贡献在于明确提出，系统级监控是LLM应用可靠运行的前提和专用事件响应框架的基础。它概述了一个基于威胁分类的监控与审计日志框架蓝图，旨在将攻击向量系统性地映射到相应的监控工件，以支持及时的威胁检测和事后取证分析，从而应对LLM应用独特的安全挑战。

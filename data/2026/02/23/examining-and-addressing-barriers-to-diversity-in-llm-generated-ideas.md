---
title: "Examining and Addressing Barriers to Diversity in LLM-Generated Ideas"
authors:
  - "Yuting Deng"
  - "Melanie Brucks"
  - "Olivier Toubia"
date: "2026-02-23"
arxiv_id: "2602.20408"
arxiv_url: "https://arxiv.org/abs/2602.20408"
pdf_url: "https://arxiv.org/pdf/2602.20408v1"
categories:
  - "cs.CY"
  - "cs.AI"
  - "cs.HC"
tags:
  - "LLM应用"
  - "Agent评测/基准"
  - "人类-AI协作"
  - "提示工程"
  - "认知心理学"
  - "创新与多样性"
relevance_score: 7.5
---

# Examining and Addressing Barriers to Diversity in LLM-Generated Ideas

## 原始摘要

Ideas generated by independent samples of humans tend to be more diverse than ideas generated from independent LLM samples, raising concerns that widespread reliance on LLMs could homogenize ideation and undermine innovation at a societal level. Drawing on cognitive psychology, we identify (both theoretically and empirically) two mechanisms undermining LLM idea diversity. First, at the individual level, LLMs exhibit fixation just as humans do, where early outputs constrain subsequent ideation. Second, at the collective level, LLMs aggregate knowledge into a unified distribution rather than exhibiting the knowledge partitioning inherent to human populations, where each person occupies a distinct region of the knowledge space. Through four studies, we demonstrate that targeted prompting interventions can address each mechanism independently: Chain-of-Thought (CoT) prompting reduces fixation by encouraging structured reasoning (only in LLMs, not humans), while ordinary personas (versus "creative entrepreneurs" such as Steve Jobs) improve knowledge partitioning by serving as diverse sampling cues, anchoring generation in distinct regions of the semantic space. Combining both approaches produces the highest idea diversity, outperforming humans. These findings offer a theoretically grounded framework for understanding LLM idea diversity and practical strategies for human-AI collaborations that leverage AI's efficiency without compromising the diversity essential to a healthy innovation ecosystem.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决大型语言模型（LLM）在集体层面生成想法时多样性不足的问题，这可能导致社会整体创新能力的同质化风险。研究背景是，尽管LLM作为构思工具在单个想法的新颖性和质量上可比拟人类，且具有知识广博、处理流畅的优势，但多个独立的LLM生成会话往往围绕相似主题收敛，探索的构思空间比人类群体更狭窄，这种现象被称为“模式崩溃”。现有方法主要依赖提示策略（如人物角色修饰、思维链提示等）来提升多样性，但存在两大不足：一是缺乏坚实的理论框架来解释为何这些策略有效以及LLM多样性不足的根本原因；二是实验比较往往缺乏严格的人类对照组，难以确定这些策略是专门缩小了人机多样性差距，还是仅仅普遍提升了生成性能。

本文要解决的核心问题是：从认知心理学理论出发，识别并实证检验阻碍LLM想法多样性的内在机制，进而设计有针对性的干预措施，以在利用AI效率优势的同时，不损害创新生态系统所必需的多样性。具体而言，论文提出了一个理论框架，指出两个关键机制：在个体层面，LLM像人类一样存在“固化”现象，即早期输出会限制后续构思；在集体层面，LLM将知识聚合为统一分布，缺乏人类群体固有的“知识分区”（即每个人占据知识空间的不同区域）。通过四项研究，论文证明针对性的提示干预可以独立应对每种机制：思维链提示通过鼓励结构化推理来减少固化（仅对LLM有效），而使用普通人物角色（而非如史蒂夫·乔布斯这类“创意企业家”）则能作为多样化的采样线索，改善知识分区，将生成锚定在语义空间的不同区域。结合这两种方法可产生最高的想法多样性，甚至超越人类水平。这些发现为理解LLM想法多样性提供了理论框架，并为人类-AI协作提供了实用策略，以在保持创新多样性的前提下发挥AI的效率。

### Q2: 有哪些相关研究？

本文的相关研究主要围绕提升LLM生成想法多样性的方法展开，可归纳为以下几类：

**方法类研究**：现有工作主要探索通过提示策略来增强LLM的想法多样性。具体包括：（1）**角色修饰提示**，例如让LLM模仿史蒂夫·乔布斯等创造性人物；（2）**思维链提示**，通过分步推理鼓励结构化思考；（3）**温度调整**，增加输出随机性，但可能损害想法质量；（4）**混合提示**，并行使用多种提示后聚合结果。这些策略虽能实证提升多样性，但缺乏理论解释，且未系统比较其对人类与LLM的差异影响。

**评测类研究**：先前研究常缺乏严格的人类对照组，或在指令、流程设计上未对齐人类与LLM的条件，导致难以区分策略是普遍提升性能还是针对性缩小多样性差距。此外，评估多依赖基于嵌入的相似度指标，可能无法准确捕捉语义层面的多样性。

本文与上述工作的关系在于：**继承并深化了方法类研究**，重点检验了思维链和角色提示的有效性；**弥补了评测类研究的不足**，通过严格控制实验条件实现“苹果对苹果”的比较，并引入基于LLM的内容分类方法以更准确衡量多样性。区别在于：本文首次从认知心理学理论出发，提出**固定化**和**知识聚合**两大机制解释LLM多样性不足的根源，并据此优化策略——例如发现普通角色比“创造性企业家”角色更能促进知识分区，且结合思维链与普通角色可使LLM多样性超越人类。这为现有方法提供了理论框架，并开辟了针对性干预的新路径。

### Q3: 论文如何解决这个问题？

论文通过借鉴认知心理学中“思维定势”和“知识分区”两个核心机制，系统地分析并解决了LLM生成想法多样性不足的问题。其解决方案是一个包含诊断和干预的双层框架，核心是通过针对性的提示工程策略分别应对这两个机制，最终结合两者以最大化多样性。

**整体框架与核心方法**：
研究首先基于LLM的三阶段流程（预训练、后训练对齐、推理）分析了多样性缺失的根源。在推理阶段，自回归生成方式可能导致早期输出锚定后续内容，类似人类的思维定势；而在预训练和对齐阶段，海量数据被聚合为单一概率分布，抹杀了人类群体中固有的知识分区特性。针对这两个独立机制，论文设计了相应的提示干预策略。

**主要模块与关键技术**：
1.  **针对思维定势的干预——链式思维提示**：研究采用特定的链式思维提示来打破定势。具体操作分为三步：首先让模型生成一系列简短的想法标题；接着明确指令模型修改这些标题以确保它们彼此不同；最后将修改后的标题扩展为完整想法。该技术通过两个关键点起作用：生成标题而非完整想法，避免了早期详细阐述对后续生成的锚定效应；明确的“使想法不同”的指令，对抗了RLHF带来的典型性偏差，迫使模型偏离主导轨迹。

2.  **针对知识分区缺失的干预——普通人设提示**：为了在LLM中模拟人类的知识分区，研究采用“普通人设”作为多样化的采样线索。例如，提示模型“从一个喜欢园艺的会计师的角度”或“从一个业余马拉松运动员的护士的角度”进行思考。与使用“史蒂夫·乔布斯”这类高度特化的“创意企业家”人设相比，普通人设能更有效地将生成过程锚定在语义空间的不同区域，从而在集体层面产生更分散、更多样的初始想法，模仿了人类因不同经验和知识结构而产生的思维路径分化。

**创新点与组合策略**：
论文的创新点在于将认知心理学理论机制与LLM技术特性直接关联，并提供了经实验验证的、可操作的提示策略。一个关键的发现是，链式思维提示主要提升**个体内**（同一个LLM实例生成的想法之间）的多样性，而普通人设提示主要提升**个体间**（不同LLM实例或不同人设之间）的多样性。因此，研究最终提出将两种策略**结合使用**：先为每个LLM实例分配一个独特的普通人设，再在其生成过程中应用链式思维提示。实验表明，这种组合策略产生的想法多样性最高，甚至能够超越人类群体的表现。这为构建人机协作的创新生态系统提供了兼顾效率与多样性的实用方案。

### Q4: 论文做了哪些实验？

该论文通过四项研究进行了实验。实验设置方面，研究要求人类参与者和LLM（使用GPT-4o模型）各自独立生成十个健身产品创意，每个创意用一句话描述，并采用序列生成方式以模拟真实构思过程。数据集/基准测试基于自行收集的创意文本，并未使用外部标准数据集。对比方法主要包括：默认LLM生成、使用“普通人物角色”提示、使用思维链提示以及组合使用两者，并与人类生成结果进行对比。

主要结果如下：研究1证实了问题，即LLM在集体层面产生的创意多样性低于人类，并识别出两个机制——个体层面的“思维定势”和集体层面的“知识聚合”。研究2发现，仅提供初始创意种子并不能改善LLM的后续多样性。研究3表明，使用具有不同背景的“普通人物角色”提示能有效模拟人类的知识分区，从而缩小与人类的多样性差距，但会加剧个体会话内的思维定势。研究4则发现，思维链提示能有效减少LLM的思维定势（对人类无效），而将思维链与普通人物角色结合时，能产生最高的创意多样性，甚至超过人类水平。

关键数据指标包括三个多样性度量：累积覆盖类别数（最大28）、累积类别组合数（最大810）以及平均成对距离（最大3.0）。具体结果中，组合干预使LLM的多样性超越了人类基准。

### Q5: 有什么可以进一步探索的点？

该论文揭示了LLM在生成想法时存在固化和知识同质化两大局限，导致其想法多样性低于人类群体。未来研究可从以下方向深入：首先，探索更复杂的干预机制，如动态角色模拟或跨文化知识注入，以增强LLM的知识分区能力；其次，将研究扩展到多轮对话和长期协作场景，检验干预策略的持续效果。此外，可结合认知科学设计更精细的评估指标，不仅衡量想法的表面多样性，还需评估其创新性和实用性。最后，需关注伦理风险，如角色设定可能带来的偏见强化问题，并开发兼顾多样性、公平性和可控性的生成框架。

### Q6: 总结一下论文的主要内容

该论文探讨了LLM生成想法多样性不足的问题，指出人类独立样本产生的想法通常比LLM样本更多样，长期依赖LLM可能导致思维同质化并损害社会创新。论文从认知心理学角度识别了两个机制：个体层面，LLM像人类一样存在“固化”现象，早期输出会限制后续构思；集体层面，LLM将知识整合为统一分布，而人类群体则存在知识分区，每人占据知识空间的不同区域。通过四项研究，论文提出针对性提示干预方法：思维链提示通过结构化推理减少固化（仅对LLM有效），而使用普通人物角色（而非“创意企业家”）作为多样采样线索，可改善知识分区，将生成锚定在语义空间的不同区域。结合两种方法能实现最高的想法多样性，甚至超越人类表现。这些发现为理解LLM想法多样性提供了理论框架，并为人类-AI协作提供了实用策略，在保持AI效率的同时不损害创新生态所需的多样性。

---
title: "Emergent Manifold Separability during Reasoning in Large Language Models"
authors:
  - "Alexandre Polo"
  - "Chanwoo Chun"
  - "SueYeon Chung"
date: "2026-02-23"
arxiv_id: "2602.20338"
arxiv_url: "https://arxiv.org/abs/2602.20338"
pdf_url: "https://arxiv.org/pdf/2602.20338v1"
categories:
  - "cs.LG"
tags:
  - "LLM Reasoning"
  - "Representation Geometry"
  - "Chain-of-Thought"
  - "Manifold Theory"
  - "Interpretability"
relevance_score: 6.5
---

# Emergent Manifold Separability during Reasoning in Large Language Models

## 原始摘要

Chain-of-Thought (CoT) prompting significantly improves reasoning in Large Language Models, yet the temporal dynamics of the underlying representation geometry remain poorly understood. We investigate these dynamics by applying Manifold Capacity Theory (MCT) to a compositional Boolean logic task, allowing us to quantify the linear separability of latent representations without the confounding factors of probe training. Our analysis reveals that reasoning manifests as a transient geometric pulse, where concept manifolds are untangled into linearly separable subspaces immediately prior to computation and rapidly compressed thereafter. This behavior diverges from standard linear probe accuracy, which remains high long after computation, suggesting a fundamental distinction between information that is merely retrievable and information that is geometrically prepared for processing. We interpret this phenomenon as \emph{Dynamic Manifold Management}, a mechanism where the model dynamically modulates representational capacity to optimize the bandwidth of the residual stream throughout the reasoning chain.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在探究大语言模型在思维链（CoT）提示下进行推理时，其内部表征几何结构的动态演化机制。研究背景是，虽然CoT已被证明能显著提升大语言模型解决复杂组合问题的能力，但其背后的时间处理机制——即模型如何利用递归生成的令牌在时间维度上处理信息——仍不明确。现有方法，如线性探针，常被用于分析中间答案的解码性，但存在固有局限：它们可能高估模型的实际知识，甚至在随机特征上也能表现出高准确率，且无法区分信息是“可检索”还是“几何上已准备好用于计算”。

针对这些不足，本文的核心问题是：在CoT推理过程中，潜在表征的几何结构（特别是线性可分性）如何随时间（令牌序列）动态变化？论文通过引入流形容量理论（MCT）这一无需训练分类器的几何度量框架，来量化表征的内在可分性，从而避免探针方法的混淆因素。研究发现，推理表现为一种瞬态的几何脉冲：在计算即将发生前，概念流形会迅速解缠为线性可分的子空间，随后又快速压缩。这与线性探针准确率在计算后仍长期保持高位形成对比，揭示了“可检索信息”与“为处理做好几何准备的信息”之间的根本区别。因此，本文要解决的核心问题是揭示并解释这种动态的几何调制机制（即动态流形管理），阐明模型如何通过动态调整表征容量来优化推理链中残差流的带宽使用。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：方法类、评测类和几何分析类。

在**方法类**研究中，关于思维链（CoT）的内部计算本质存在争议。有研究质疑CoT的忠实性，认为其可能是事后合理化而非真正的因果驱动因素，尤其是在小模型中，更细粒度的CoT未必提升性能。另一方面，可解释性研究已在小型注意力模型中识别出参与归纳推理的“电路”。本文通过寻找推理步骤的全局几何特征，特别是沿CoT的几何表征动态，为这一讨论做出了贡献。

在**评测类**研究中，线性探针（linear probe）是主流工具，基于“线性表征假说”，即语义概念被编码为线性子空间中的向量。探针已被用于解码各种概念，如句法深度和陈述真实性。然而，探针方法存在显著局限，如对超参数敏感，且在高维空间中即使对随机任务也能获得高准确率，这催生了寻找更几何化分析方法的必要性。

在**几何分析类**研究中，基于流形的几何分析技术在大脑和前馈网络研究中已被广泛应用和发展。其核心观点是将神经表征集合视为神经流形，而神经计算的目标是解开这些流形。**流形容量理论**（MCT）通过统计力学原理量化了这种线性可分性，将其定义为一种固有的几何属性，从而避免了探针方法的方法论缺陷。该理论在视觉/听觉皮层及人工视觉模型中已提供有用见解，观察到类别流形随网络层加深而逐步解缠。然而，其在大型语言模型（LLM）中的应用尚处于起步阶段。现有工作分析了静态词嵌入的几何特性或Transformer表征的内在维度，而本文的贡献在于将MCT应用于**时间维度**，追踪推理过程中概念流形的动态调制。

### Q3: 论文如何解决这个问题？

论文通过引入流形容量理论（MCT）来分析思维链（CoT）提示下大语言模型推理过程中的表示几何动态，从而解决“推理过程中潜在表示几何的时序动态如何演化”这一问题。核心方法是利用一个组合布尔逻辑任务作为基准，通过量化潜在表示的线性可分性，揭示推理过程中的几何脉冲现象。

整体框架基于一个高度结构化的实验设置。首先，设计了一个分层布尔逻辑任务，要求模型评估嵌套表达式（如 `((True and False) or (True xor True))`）的真值。每个表达式对应一个满二叉树，内部节点代表逻辑运算符，叶节点为布尔常量。为对齐不同任务间的表示，论文采用了严格的命名和排序方案，为每个内部节点分配唯一ID，并通过特定的提示策略确保所有任务以相同顺序解决。数据集包含256个平衡表达式（树高h=5，共31个内部节点）。

关键的技术模块和设计包括：
1.  **结构化输出与时间锚点**：通过精心设计的系统提示，强制模型以严格的Markdown格式输出，分为“问题陈述”、“求解”和“总结”三个阶段。这种结构化输出不仅提高了模型准确性（在深度5任务上达到98%），更重要的是提供了确定性的文本标记（如 `### Solve`、`* Logic:`），作为计算流形容量的“时间锚点”，用于在推理链的语义等价点对齐表示。
2.  **表示采样策略**：为避免文本污染（即模型读取自身生成文本导致的信号混淆），论文将流形容量计算和线性探测限制在特定的结构锚点上，即每个结构字符串的最后一个标记（例如 `* Result:` 中的冒号）。这个时刻是模型在生成答案文本之前、上下文信息聚合压力最大的点，能有效捕捉内部计算状态而非输出反射。
3.  **核心度量：流形容量（α）**：应用流形容量理论，直接量化潜在表示的线性可分性，无需训练探针，避免了探针训练带来的混淆因素。具体计算时，将一组对齐的残差流嵌入（对应特定结构标记）根据某个节点真值的ground truth标签进行分类，通过计算最小随机子空间维度 N* 来得到容量 α（α = 2/N*）。这提供了对表示几何“准备就绪度”的直接测量。
4.  **辅助验证：线性探针**：作为容量度量的补充，使用硬间隔支持向量机（SVM）和逻辑回归等线性分类器来分离相同的流形。硬间隔SVM的最大间隔超平面法向量方向，可作为节点真值编码方向的代表，用于分析该方向随时间或跨节点的保守性与相似性。

创新点在于发现了推理表现为一种**瞬态几何脉冲**：在计算即将发生前，概念流形被解缠为线性可分的子空间（容量α达到峰值），而在计算完成后迅速被压缩。这种行为与线性探针准确率（计算后仍长期保持高位）形成鲜明对比，揭示了“可检索信息”与“为处理做好几何准备的信息”之间的根本区别。论文将此现象解释为 **“动态流形管理”** 机制，即模型动态调制表示容量，以优化整个推理链中残差流的带宽。

### Q4: 论文做了哪些实验？

该论文通过组合布尔逻辑任务，研究了大型语言模型在思维链推理过程中表征几何的时序动态。实验设置、数据集、对比方法和主要结果如下：

**实验设置与数据集**：研究使用组合布尔逻辑任务（深度为5的树状结构）作为基准测试。模型采用Ministral 3 8B Reasoning，通过思维链提示进行推理。实验对比了两种条件：完整CoT生成（达到98%准确率）与直接要求即时答案（仅59%准确率，略高于随机猜测），以验证CoT对任务解决的功能必要性。

**对比方法与关键指标**：核心分析方法是流形容量理论，用于量化潜在表征的线性可分性，避免了线性探针训练带来的混淆因素。同时，作为对比，研究也使用了硬间隔SVM和逻辑回归线性探针来测量分类准确率。关键指标包括：**节点流形容量**（Manifold Capacity）、**线性探针测试准确率**、**局部与全局维度**（通过TwoNN和参与率估算）以及**注意力分数**。

**主要结果**：
1.  **计算信号与动态几何脉冲**：表征的线性可分性并非静态，而是呈现脉冲式轨迹。在解决特定节点时，该节点的流形容量会急剧上升（达到峰值），随后迅速衰减回基线水平。这表明信息在解决后立即从残差流中被“擦除”，以便为后续节点计算释放带宽。
2.  **可分性衰减与探针结果的背离**：节点计算完成后，其流形容量迅速衰减至接近随机基线。与此形成鲜明对比的是，线性探针的准确率在计算完成后仍能长时间保持高位（>90%，持续约两个节点）。这揭示了“可检索信息”与“几何上准备好用于处理的信息”之间的根本区别。
3.  **时空起源**：对层×时间的网格分析表明，可分性的增加起始于中间层（第13-15层），然后在结果结构标记处（答案输出前）扩展到所有深层。在后续的重组阶段，中间层的容量快速下降，深层（第16-32层）的信息可及性降低。
4.  **带宽管理与维度**：在整个CoT过程中，表征的局部和全局维度都维持在较低水平（约10维）。分析发现，解决一个节点至少需要三个维度：两个用于分离左右子节点答案（方向相对且守恒），一个用于分离当前节点答案（方向不守恒）。
5.  **注意力机制的作用**：注意力分析显示，模型在解决当前节点时，会强烈关注其子节点解决阶段的标记。更重要的是，对某个概念（源）的注意力强度与其在目标时刻的流形容量高度正相关（相关系数r=0.723）。这表明注意力机制介导了对表征几何的战略管理，当信息在残差流中不再线性可分时，通过注意力从先前标记的嵌入中获取信息。

### Q5: 有什么可以进一步探索的点？

该论文的局限性主要在于其研究基于结构可控但缺乏自然语言模糊性的合成布尔逻辑任务，未来需验证所观察到的刚性脉冲动态是否适用于非结构化领域或更大参数规模（如70B+）的模型。此外，研究依赖流形容量理论，假设模型内部步骤主要利用线性可分性，但语言模型可能依赖非线性几何机制，当前指标未能完全捕捉。

未来研究方向可包括：一、将实验扩展到真实自然语言推理任务（如数学问题、逻辑谜题），探究脉冲动态在模糊语境下的变化；二、结合非线性探测方法（如核函数、神经网络探针）分析表示几何，以更全面理解模型内部计算机制；三、探索动态流形管理机制与模型效率的关联，例如如何通过干预脉冲时序优化推理带宽；四、研究不同提示策略（如少样本、自我验证）对表示可分性的影响，为改进推理能力提供几何视角的指导。

### Q6: 总结一下论文的主要内容

这篇论文通过流形容量理论研究了大型语言模型在思维链推理过程中的内部表征几何动态。核心问题是探究推理过程中潜在表征的线性可分性如何随时间变化，以区分信息是“可检索”还是“几何上已准备好用于计算”。

方法上，作者将流形容量理论应用于组合布尔逻辑任务，量化了潜在表征的线性可分性，避免了探针训练的混淆因素，并进行了层间和时间点的动态分析。

主要结论揭示了推理表现为一种瞬态的几何脉冲：在计算即将发生前，概念流形被解缠为线性可分的子空间，随后迅速压缩。这与线性探针精度长期保持高位形成对比，表明信息保留与计算就绪状态存在根本区别。作者将此现象解释为“动态流形管理”机制，即模型通过动态调制表征容量，在推理链中优化残差流的带宽，将计算负载分布到时间维度上，从而在固定维度的约束下高效处理复杂推理任务。

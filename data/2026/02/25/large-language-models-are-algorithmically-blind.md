---
title: "Large Language Models are Algorithmically Blind"
authors:
  - "Sohan Venkatesh"
  - "Ashish Mahendran Kurapath"
  - "Tejas Melkote"
date: "2026-02-25"
arxiv_id: "2602.21947"
arxiv_url: "https://arxiv.org/abs/2602.21947"
pdf_url: "https://arxiv.org/pdf/2602.21947v1"
categories:
  - "cs.CL"
tags:
  - "LLM能力评估"
  - "算法推理"
  - "因果发现"
  - "程序性知识"
  - "基准测试"
relevance_score: 5.5
---

# Large Language Models are Algorithmically Blind

## 原始摘要

Large language models (LLMs) demonstrate remarkable breadth of knowledge, yet their ability to reason about computational processes remains poorly understood. Closing this gap matters for practitioners who rely on LLMs to guide algorithm selection and deployment. We address this limitation using causal discovery as a testbed and evaluate eight frontier LLMs against ground truth derived from large-scale algorithm executions and find systematic, near-total failure. Models produce ranges far wider than true confidence intervals yet still fail to contain the true algorithmic mean in the majority of instances; most perform worse than random guessing and the marginal above-random performance of the best model is most consistent with benchmark memorization rather than principled reasoning. We term this failure algorithmic blindness and argue it reflects a fundamental gap between declarative knowledge about algorithms and calibrated procedural prediction.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在探究大语言模型（LLM）在算法性能预测方面的能力缺陷，即所谓的“算法盲性”。研究背景是，尽管LLMs展现出广泛的知识覆盖，但其对计算过程的推理能力尚不明确，而这对依赖LLM进行算法选择和部署的实践者至关重要。现有方法通常假设LLMs能够基于问题结构进行零样本算法推荐或不确定性估计，但缺乏系统评估来验证这些推荐是否具有校准的定量有效性，还是仅仅依赖于训练文本中的模式匹配，在数值严谨性下容易失效。

本文的核心问题是：LLMs能否仅从问题结构出发，形成对算法性能的校准概率预测？为回答此问题，研究以因果发现作为测试平台，因为它涉及多种算法范式、标准化指标和可控制的数据生成，能有效区分模型是进行真正的结构条件泛化，还是仅仅记忆基准数据。通过大规模实验评估八个前沿LLM，论文发现它们存在系统性、近乎完全的失败：模型预测的范围远宽于真实置信区间，却仍无法在多数情况下包含真实算法均值，大多数模型表现甚至差于随机猜测，而最佳模型的略高于随机的性能更可能与基准记忆而非原则性推理一致。因此，论文揭示了LLMs在从问题结构到校准程序预测之间存在根本性差距，这限制了其作为可靠算法选择工具的实用性。

### Q2: 有哪些相关研究？

本文的相关工作主要可分为算法选择、大语言模型推理能力评估、以及校准研究三类。

在算法选择领域，早期研究如Rice的形式化工作，以及后续基于元学习的方法，通过训练预测器利用算法历史性能数据进行选择，应用于SAT求解器、组合优化器等。AutoML系统（如Auto-WEKA）进一步利用贝叶斯优化进行算法配置。本文与这些工作的关系在于共享“预测算法性能”这一核心问题，但区别在于本文评估的是LLMs基于其内部知识（而非历史数据）进行预测的零样本能力，而非训练一个专门的预测模型。

在大语言模型推理评估方面，已有研究探讨了LLMs在数学、科学推理上的表现，发现其易受分布偏移影响，暗示其依赖模式匹配而非符号推理。近期也有工作探索LLM作为科学任务助手，如在定性排序算法或方法推荐上展现潜力。本文与此类研究直接相关，但提供了新的定量视角和具体的失败案例：本文发现，尽管LLMs能定性识别算法类型，但在定量预测具体数据集上的算法性能时却系统性失败，这揭示了其“算法性盲视”这一新缺陷。

在校准研究领域，已有工作表明LLMs在分类任务中存在置信度与准确率错位的校准不良问题。本文与之紧密相关，并将校准概念延伸至区间预测场景，评估LLM给出的置信区间是否包含真实算法性能均值的频率是否与声称的置信水平匹配，结果发现其校准同样失败。

### Q3: 论文如何解决这个问题？

论文通过一个严谨的五阶段评估流程来系统性地揭示和量化大语言模型在算法性能预测上的“算法性盲视”问题，并探究其根源。

**核心方法与整体框架**：研究构建了一个以大规模算法执行结果作为客观事实基准的评估管道。首先，针对13个数据集（9个标准基准数据集和4个合成数据集）与4种因果发现算法（PC、FCI、LiNGAM、NOTEARS）的52种组合，各进行100次带自助重采样的算法运行，计算每次运行的精确度、召回率、F1和结构汉明距离，从而得到每个实验条件下性能指标的经验均值及其95%置信区间，作为评估LLMs的“地面真值”。

**主要模块与关键技术**：
1.  **查询与预测收集**：向8个前沿LLM（如Claude Opus、GPT-5、DeepSeek等）发起查询。针对每个实验条件，使用三种不同措辞的提示（直接提问、扩展描述、强调不确定性）来让模型预测四个性能指标的可能范围。这产生了1248次API调用，以降低对特定措辞的敏感性。
2.  **聚合与校准覆盖度比较**：将每个模型对同一条件的三种提示预测范围进行平均，得到聚合预测区间。核心评估指标是**校准覆盖度**，即计算LLM的聚合预测区间包含真实算法均值的比例（在1664个模型-数据集-算法-指标组合上）。这直接回答了“LLM给出的范围对实践者是否有用”这一操作性问题。
3.  **基线评估**：设立两个基线作为参考点：**随机基线**（在指标有效域内均匀随机生成预测范围）和**启发式基线**（利用文献中的保守数据集统计量构建范围）。这确保了LLM的性能是相对于“无推理”能力进行评估的。
4.  **鲁棒性与深入分析**：
    *   **提示敏感性分析**：通过计算同一模型-指标-实验下三种提示预测的变异系数，量化模型对提示措辞的敏感度。
    *   **算法特异性与泛化分析**：比较模型在已知基准数据集和全新合成数据集上的覆盖度表现。若在合成数据上性能普遍下降，可能表明泛化困难；若仅在训练数据中曝光少的算法上表现差，则指向记忆而非理解。
    *   **记忆化探测分析**：通过三项分析探究模型行为是否源于记忆：分析算法与指标在覆盖度上的交互模式；比较模型对基准数据和合成数据预测区间的宽度（记忆会导致对基准数据预测更“自信”、区间更窄）；计算不同模型对同一条件预测范围的平均成对距离（记忆会导致模型在基准数据上预测趋同，在合成数据上发散）。

**创新点**：
1.  **问题定义与量化**：首次系统性地提出并量化了LLMs在**算法性能预测**这一具体推理任务上的“算法性盲视”，即模型拥有关于算法的陈述性知识，但无法做出经过校准的程序性预测。
2.  **严谨的评估范式**：构建了以大规模算法执行结果为金标准、包含多种提示、多个基线、以及针对记忆化效应的多角度探测的综合性评估框架，超越了简单的准确率比较。
3.  **超越表面性能的归因分析**：研究不仅报告了LLMs在该任务上系统性失败（多数表现差于随机猜测），还通过精心设计的合成数据对比、预测区间宽度分析和模型间一致性检查，有力地论证了最佳模型的有限超出随机水平的性能，更可能与**对基准统计数据的记忆**有关，而非基于原理的推理。这揭示了当前LLM知识能力中的一个根本性缺口。

### Q4: 论文做了哪些实验？

该论文以因果发现算法为测试平台，评估了八个前沿大语言模型（LLMs）预测算法性能的能力。实验设置要求模型为四种因果发现算法（PC、FCI、LiNGAM、NOTEARS）在多个数据集上的四个性能指标（精确度、召回率、F1分数、结构汉明距离）预测一个置信区间，并与基于大规模算法执行得到的真实性能均值进行对比。

**数据集/基准测试**：使用了9个真实世界基准数据集（如Asia、Cancer、Alarm等）和4种规模的合成数据集（12、30、50、60个节点），共计1664次比较。

**对比方法与主要结果**：
1.  **主要指标**：校准覆盖率（Calibrated Coverage），即预测区间包含真实算法均值的比例。所有模型的平均覆盖率仅为15.9%，失败率高达84.1%。
2.  **模型对比**：Claude表现最佳，覆盖率为39.4%，但仍远低于可靠指导所需的水平。GPT-5、DeepSeek系列、Qwen系列、Gemini 3和LLaMA的覆盖率在5.8%至15.4%之间。七个模型的表现均低于随机猜测基线（36.5%）。
3.  **算法与指标分析**：所有算法和指标的覆盖率均低于21%。模型在召回率（18.8%）和精确度（13.5%）预测上的差异表明其系统性地高估真阳性率、低估假阳性率。
4.  **合成数据与基准数据对比**：在未见于训练数据的合成数据集上，模型平均覆盖率（11.7%）比基准数据集（17.7%）低34%，且覆盖率随合成网络规模增大而单调下降（从12节点的20.3%降至60节点的6.2%），表明模型依赖对训练数据中基准统计结果的记忆，而非泛化推理。
5.  **其他关键发现**：
    *   模型预测的区间宽度是真实置信区间的8到27倍，但覆盖率仍然极低，表明其信念严重失准。
    *   在基准数据集上，模型预测的区间宽度明显更窄（平均压缩比2.26倍），且模型间预测一致性更高，进一步支持了记忆假说。
    *   不同提示词会导致结果显著波动（变异系数最高超过100%），表明模型对算法性能的“信念”极不稳定。

### Q5: 有什么可以进一步探索的点？

该论文揭示了LLMs在算法性能预测上的系统性失败，即“算法性盲视”。未来研究可从多个维度深入探索：首先，需通过训练数据归因等方法，实证检验模型表现是源于基准记忆还是真正推理。其次，应拓展测试范围至SAT求解、图算法等更多计算领域，以判断此盲视是因果发现任务特有还是LLMs的普遍局限。再者，可尝试对算法执行历史进行微调，以区分根本性能力缺陷与可弥补的数据缺口。方法上，可探索将LLMs作为特征提取器，与统计模型结合，构建兼具语言理解与校准预测的混合系统。此外，需对比人类专家在相同任务上的表现，若专家显著优于随机，则可为LLMs设立明确的能力提升目标；若专家也接近随机，则说明问题本身具有根本性难度，需重新定义评估范式。这些方向将有助于厘清LLMs推理能力的边界，并推动更具鲁棒性的算法认知模型的发展。

### Q6: 总结一下论文的主要内容

该论文探讨了大型语言模型在算法性能预测方面的局限性，提出了“算法性盲视”的概念。研究以因果发现算法为测试平台，评估了八个前沿LLM基于大规模算法执行结果进行预测的能力。核心问题是LLM是否具备对计算过程的推理能力，以辅助算法选择和部署。

方法上，研究将LLM的预测与真实算法性能的基准数据（通过大规模执行获得）进行系统比较，评估其预测区间是否包含真实算法均值以及预测的校准情况。

主要结论是，LLM表现出系统性失败：绝大多数预测未能包含真实均值，多数模型表现甚至差于随机猜测；唯一表现略优于随机的模型，其能力更可能源于对基准数据的记忆而非原理性推理。LLM给出的预测区间远宽于真实置信区间却仍存在系统性误校准。这揭示了LLM的陈述性算法知识与经过校准的程序性预测能力之间存在根本性差距，表明当前LLM不适合作为算法性能预测器直接部署，强调了在实际应用前进行严格实证评估的必要性。

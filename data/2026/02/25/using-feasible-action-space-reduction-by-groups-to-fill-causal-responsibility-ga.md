---
title: "Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions"
authors:
  - "Vassil Guenov"
  - "Ashwin George"
  - "Arkady Zgonnikov"
  - "David A. Abbink"
  - "Luciano Cavalcante Siebert"
date: "2026-02-25"
arxiv_id: "2602.22041"
arxiv_url: "https://arxiv.org/abs/2602.22041"
pdf_url: "https://arxiv.org/pdf/2602.22041v1"
categories:
  - "cs.MA"
  - "cs.CY"
tags:
  - "多智能体系统"
  - "因果责任"
  - "空间交互"
  - "自主系统"
  - "责任度量"
  - "群体智能"
  - "人机交互"
  - "自动驾驶"
relevance_score: 7.5
---

# Using Feasible Action-Space Reduction by Groups to fill Causal Responsibility Gaps in Spatial Interactions

## 原始摘要

Heralding the advent of autonomous vehicles and mobile robots that interact with humans, responsibility in spatial interaction is burgeoning as a research topic. Even though metrics of responsibility tailored to spatial interactions have been proposed, they are mostly focused on the responsibility of individual agents. Metrics of causal responsibility focusing on individuals fail in cases of causal overdeterminism -- when many actors simultaneously cause an outcome. To fill the gaps in causal responsibility left by individual-focused metrics, we formulate a metric for the causal responsibility of groups. To identify assertive agents that are causally responsible for the trajectory of an affected agent, we further formalise the types of assertive influences and propose a tiering algorithm for systematically identifying assertive agents. Finally, we use scenario-based simulations to illustrate the benefits of considering groups and how the emergence of group effects vary with interaction dynamics and the proximity of agents.

## Q&A 论文解读

### Q1: 这篇论文试图解决什么问题？

这篇论文旨在解决多智能体空间交互（例如自动驾驶汽车、移动机器人）中，因果责任归因的“责任空白”问题。研究背景是，随着自主系统与人类交互日益频繁，如何界定交互中的责任变得至关重要。现有方法主要基于“可行行动空间缩减”等指标，聚焦于个体智能体的责任。然而，这些个体责任度量存在明显不足：在因果过度决定情形下（即多个行动者同时导致某一结果时），单个智能体的行动可能并不足以被视为结果的唯一原因，导致无法将责任合理地归因于任何个体，从而产生“责任空白”。

本文的核心问题是：如何填补因过度依赖个体责任度量而导致的因果责任空白。为此，论文提出将责任分析从个体扩展到群体。具体而言，论文重新制定了可行行动空间缩减指标，以量化群体对受影响智能体轨迹的因果责任；形式化地分类了不同类型的“主张性影响”；并提出了一种分层算法来系统识别具有因果责任的主张性智能体。通过模拟实验，论文进一步展示了考虑群体责任的必要性，以及群体效应如何随交互动力学和智能体间距离而变化。

### Q2: 有哪些相关研究？

本文的相关研究主要可分为三类：责任建模方法类、空间交互应用类以及群体责任理论类。

在**责任建模方法**方面，已有研究提出了基于“可行行动空间缩减”（FeAR）的因果责任形式化模型，用于量化个体智能体对其他智能体轨迹的影响。然而，这些方法仅聚焦于个体责任，在因果过度决定（多个行动者同时导致结果）的情况下会失效，造成“责任空白”。本文正是在此基础上，将FeAR指标扩展至**群体责任**的量化，填补了这一空白。

在**空间交互应用**领域，大量工作集中于“负责任”或“责任感知”的导航策略，例如研究智能体如何相互礼让。这些方法通常缺乏严格的责任形式化定义，而本文则提供了基于FeAR的严谨数学模型，并进一步通过场景仿真验证了群体责任在复杂空间交互（如自动驾驶汽车与行人交互）中的重要性。

在**群体责任理论**方面，已有形式化模型尝试将集体结果的责任分配到个体，但多局限于动作空间有限的抽象场景，难以扩展到连续、复杂的空间交互中。本文提出的群体FeAR指标及断言影响分类与分级算法，能够系统处理多智能体协同作用的超加性影响，为实际空间交互中的责任归属提供了可扩展的计算框架。

### Q3: 论文如何解决这个问题？

论文通过提出一种基于群体的可行行动空间缩减（FeAR）度量方法，来解决因果责任分配中因因果过度决定（多个行动者同时导致结果）而个体度量失效的问题。核心方法是扩展原有的个体FeAR度量，引入群体FeAR（gFeAR）以量化群体对受影响智能体的因果责任。

整体框架基于网格世界模型，其中多个智能体在空间中进行交互。每个智能体具有包含17个动作（方向与速度组合）的动作空间。关键概念是“例行移动”（MdR），代表在给定状态下智能体的预期行为。通过反事实干预——将实际动作替换为MdR——来评估行动者对受影响智能体可行行动空间的限制程度。

主要模块与关键技术包括：
1.  **群体FeAR（gFeAR）度量公式**：定义为 \( \text{FeAR}_{G, j} = (\eta_{j}^{\text{MdR}_G} - \eta_j) / (\eta_{j}^{\text{MdR}_G} + \epsilon) \)。其中，\( G \) 是非空的行动者群体，\( j \) 是受影响智能体，\( \eta_j \) 是实际联合动作下 \( j \) 的可行移动数，\( \eta_{j}^{\text{MdR}_G} \) 是将群体 \( G \) 中所有成员动作替换为其MdR后 \( j \) 的可行移动数。该公式直接量化了群体集体行动对 \( j \) 行动空间的缩减程度，正值表示群体对 \( j \) 的轨迹具有断言性因果责任。
2.  **断言性影响类型的形式化分类**：为了精细刻画智能体如何施加影响，论文定义了四种影响类型：
    *   **单独影响**：单个智能体自身即对受影响者产生正的个体FeAR。
    *   **耦合影响**：群体中每个成员单独对受影响者的个体FeAR为零，但作为集体（gFeAR）产生正的影响。这直接捕捉了因果过度决定的情形。
    *   **中介影响**：单个智能体自身个体FeAR为零，但存在一个非空群体 \( G \)，使得当该智能体加入 \( G \) 时，群体对受影响者的gFeAR大于 \( G \) 自身的gFeAR。这表明其影响需要通过其他中介者实现。
    *   **中介耦合影响**：上述耦合影响的中介版本，即一个群体 \( G \) 的影响需要通过另一个群体 \( G' \) 才得以显现。
3.  **分层排序算法**：为了系统性地识别对受影响智能体具有断言性因果责任的最小群体，并理清复杂的影响依赖关系，论文提出了一种迭代算法。该算法将候选行动者（非 courteous 的智能体）按影响力大小分层。核心步骤是：从最小的群体大小（k=1）开始，遍历所有大小为k的候选群体子集；如果一个群体 \( G \) 与之前所有层已识别出的行动者集合 \( \mathcal{R}_{n-1} \) 合并后，能增加对受影响者 \( j \) 的gFeAR值，则将该群体 \( G \) 加入当前层 \( \text{Tier}_j(n) \)，并将其成员从后续候选者中移除。算法逐层进行，直到没有新的断言性群体被发现。这种分层确保了具有直接（或中介）影响的行动者被排在更高层（更具影响力）。

创新点在于：
*   **从个体到群体的度量拓展**：首次在空间交互的因果责任量化中，系统性地提出了群体层面的责任度量公式，有效填补了因果过度决定场景下的责任分配空白。
*   **影响类型的精细理论框架**：通过形式化定义四种影响类型，为理解智能体间复杂的交互模式（如协同、中介）提供了清晰的概念工具和分析图谱。
*   **系统性的影响分层方法**：提出的算法能够自动、结构化地揭示出对受影响者轨迹负有因果责任的关键个体和群体，并按其影响力强度进行排序，增强了责任归因的可解释性和实用性。

### Q4: 论文做了哪些实验？

论文通过基于场景的仿真实验，验证了所提出的群体因果责任度量（group FeAR）和分层算法的有效性。实验设置方面，研究者设计了多个交互场景，包括一个详细场景（S1：机器人穿越行人）和三个伪随机仿真场景（S2：激进型、S3：定向型、S4：随机型）。每个场景包含8个智能体，对S2-S4每个场景运行50次仿真，每次仿真进行5次迭代，共产生每个场景250个独立案例。

实验使用两个核心指标进行评估：1）识别的自信智能体数量差异（δAssertive = 群体FeAR识别的数量 - 个体FeAR识别的数量）；2）使用肯德尔τ系数比较自信度排名的对齐程度，将个体FeAR排名（fearRanks）和群体分层排名（tierRanks）与基于沙普利值（ShapRanks）的基准排名进行对比。此外，实验还分析了这些指标与智能体邻近度（以曼哈顿距离中位数衡量）的关系。

主要结果显示，群体FeAR能够识别出比个体FeAR更多的自信智能体（δAssertive > 0），尤其是在智能体距离较近（曼哈顿距离中位数较小）的场景中，群体效应更为显著。在排名一致性方面，肯德尔τ分析表明，基于群体分层（tierRanks）的排名与沙普利值基准（ShapRanks）具有可比性。具体场景S1的分析表明，对于不同受影响智能体，群体方法能系统地揭示个体、耦合及中介等多种自信影响类型。这些实验共同证明了在空间交互中考虑群体责任，能够弥补仅关注个体责任的度量方法的不足，特别是在因果过度决定的情形下。

### Q5: 有什么可以进一步探索的点？

本文提出的群体因果责任度量方法虽能有效弥补个体视角在因果过度决定场景下的不足，但仍存在若干局限和可拓展方向。首先，其群体识别算法依赖于预设的“断言性影响”分类与分层机制，在复杂动态环境中可能无法充分捕捉隐性的协作或对抗关系，未来可引入数据驱动的群体发现方法（如基于注意力机制的交互建模）来自适应识别责任群体。其次，模拟验证集中于特定交互场景，缺乏在真实人机混合环境（如密集城市交通）中的验证，需通过实际机器人平台或人类行为数据进行实证研究。此外，责任度量未考虑时间尺度上的累积效应与责任分配公平性问题，可结合博弈论或伦理框架，探索动态责任分摊机制。最后，该方法尚未与现有自动驾驶责任评估标准（如ISO 21448）衔接，未来工作可尝试构建跨学科的评估体系，以推动其在政策与法规层面的应用。

### Q6: 总结一下论文的主要内容

该论文针对自动驾驶和移动机器人等自主系统与人类进行空间交互时的责任归属问题展开研究。现有责任度量方法主要关注个体智能体，但在因果过度决定（即多个行为者同时导致某一结果）的情况下存在局限。为填补这一空白，论文提出了一个用于度量群体因果责任的指标。核心贡献在于：首先，形式化了群体因果责任的概念，以解决个体责任度量无法覆盖的因果责任缺口；其次，为识别对受影响智能体轨迹具有因果责任的“主导型”智能体，论文进一步形式化了主导影响的类型，并提出了一种分层算法来系统性地识别这些智能体。方法上，通过基于场景的仿真实验，展示了考虑群体责任的优势，并分析了群体效应如何随交互动态和智能体间距离的变化而显现。主要结论是，所提出的群体责任度量能够更全面地评估复杂空间交互中的责任分配，尤其在多智能体共同导致结果的场景中，为责任认定提供了更合理的框架，对自动驾驶系统的安全与伦理评估具有重要意义。
